2025-07-15T14:22:51,466 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-07-15T14:22:51,466 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-07-15T14:22:51,518 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-07-15T14:22:51,518 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-07-15T14:22:51,648 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.0
TS Home: /opt/conda/lib/python3.10/site-packages
Current directory: /opt/ml/code
Temp directory: /home/model-server/tmp
Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 48
Max heap size: 30688 M
Python executable: /opt/conda/bin/python3.10
Config file: /etc/sagemaker-ts.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8080
Metrics address: http://127.0.0.1:8082
Model Store: /opt/ml/code/.sagemaker/ts/models
Initial Models: model=/opt/ml/model
Log dir: /opt/ml/code/logs
Metrics dir: /opt/ml/code/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 48
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: true
Workflow Store: /opt/ml/code/.sagemaker/ts/models
Model config: N/A
2025-07-15T14:22:51,648 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.0
TS Home: /opt/conda/lib/python3.10/site-packages
Current directory: /opt/ml/code
Temp directory: /home/model-server/tmp
Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 48
Max heap size: 30688 M
Python executable: /opt/conda/bin/python3.10
Config file: /etc/sagemaker-ts.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8080
Metrics address: http://127.0.0.1:8082
Model Store: /opt/ml/code/.sagemaker/ts/models
Initial Models: model=/opt/ml/model
Log dir: /opt/ml/code/logs
Metrics dir: /opt/ml/code/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 48
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: true
Workflow Store: /opt/ml/code/.sagemaker/ts/models
Model config: N/A
2025-07-15T14:22:51,654 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-07-15T14:22:51,654 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-07-15T14:22:51,670 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model
2025-07-15T14:22:51,670 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model
2025-07-15T14:22:51,672 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:22:51,672 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:22:51,672 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:22:51,672 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:22:51,675 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.
2025-07-15T14:22:51,675 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.
2025-07-15T14:22:51,886 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-07-15T14:22:51,886 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-07-15T14:22:52,134 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-07-15T14:22:52,134 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-07-15T14:22:52,135 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-07-15T14:22:52,135 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-07-15T14:22:52,158 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-07-15T14:22:52,158 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-07-15T14:22:53,913 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=173
2025-07-15T14:22:53,914 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:22:53,919 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=318
2025-07-15T14:22:53,921 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:53,923 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:53,924 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]173
2025-07-15T14:22:53,924 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:53,925 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:53,930 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:22:53,930 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:22:53,933 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:53,934 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]318
2025-07-15T14:22:53,935 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:53,935 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:53,935 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:53,935 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:53,964 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:22:53,964 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9031.
2025-07-15T14:22:53,969 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589373969
2025-07-15T14:22:53,969 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589373969
2025-07-15T14:22:53,969 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589373969
2025-07-15T14:22:53,969 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589373969
2025-07-15T14:22:53,978 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=183
2025-07-15T14:22:53,980 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:22:53,986 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=159
2025-07-15T14:22:53,987 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:22:53,996 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:53,997 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]183
2025-07-15T14:22:53,998 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:53,999 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:22:53,999 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:22:53,999 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,005 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=346
2025-07-15T14:22:54,005 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:54,007 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9025.
2025-07-15T14:22:54,007 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374007
2025-07-15T14:22:54,007 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374007
2025-07-15T14:22:54,012 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,012 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]159
2025-07-15T14:22:54,013 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,013 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,013 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:22:54,013 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:22:54,023 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,024 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]346
2025-07-15T14:22:54,025 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,025 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,025 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:54,025 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:54,031 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374031
2025-07-15T14:22:54,031 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:22:54,031 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374031
2025-07-15T14:22:54,037 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,045 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,046 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,049 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=139
2025-07-15T14:22:54,050 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374050
2025-07-15T14:22:54,050 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:22:54,050 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9041.
2025-07-15T14:22:54,050 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374050
2025-07-15T14:22:54,065 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,073 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]139
2025-07-15T14:22:54,076 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:22:54,077 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,076 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:22:54,079 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9026, pid=236
2025-07-15T14:22:54,080 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:54,080 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9043, pid=347
2025-07-15T14:22:54,081 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:22:54,085 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,086 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=140
2025-07-15T14:22:54,087 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:22:54,105 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,106 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374106
2025-07-15T14:22:54,106 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=160
2025-07-15T14:22:54,105 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,107 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:22:54,107 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - [PID]236
2025-07-15T14:22:54,106 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,107 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2025-07-15T14:22:54,108 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,108 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,109 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,106 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374106
2025-07-15T14:22:54,111 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,112 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - [PID]347
2025-07-15T14:22:54,106 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]140
2025-07-15T14:22:54,112 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]160
2025-07-15T14:22:54,112 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,112 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:22:54,112 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:22:54,112 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,112 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:22:54,112 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:22:54,113 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,112 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:22:54,112 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:22:54,112 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,114 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,113 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:54,112 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,113 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:54,116 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:22:54,110 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9024, pid=181
2025-07-15T14:22:54,117 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=355
2025-07-15T14:22:54,118 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:22:54,118 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:22:54,118 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9033, pid=323
2025-07-15T14:22:54,118 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9043.
2025-07-15T14:22:54,118 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374118
2025-07-15T14:22:54,118 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374118
2025-07-15T14:22:54,118 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:22:54,119 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374119
2025-07-15T14:22:54,119 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374119
2025-07-15T14:22:54,119 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:22:54,119 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374119
2025-07-15T14:22:54,119 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374119
2025-07-15T14:22:54,121 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=145
2025-07-15T14:22:54,122 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:22:54,119 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9035, pid=328
2025-07-15T14:22:54,130 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:22:54,129 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9023, pid=180
2025-07-15T14:22:54,130 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:22:54,129 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=163
2025-07-15T14:22:54,130 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,131 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:22:54,131 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,131 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - [PID]323
2025-07-15T14:22:54,131 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,132 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - [PID]355
2025-07-15T14:22:54,131 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=148
2025-07-15T14:22:54,132 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,132 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:22:54,142 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:22:54,144 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,142 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,136 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9028, pid=276
2025-07-15T14:22:54,144 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:22:54,144 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9026.
2025-07-15T14:22:54,144 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374144
2025-07-15T14:22:54,132 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:22:54,144 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374144
2025-07-15T14:22:54,144 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:22:54,140 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9042, pid=345
2025-07-15T14:22:54,137 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9027, pid=248
2025-07-15T14:22:54,145 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:22:54,145 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:22:54,145 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=143
2025-07-15T14:22:54,141 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,145 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,145 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]163
2025-07-15T14:22:54,144 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,145 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,145 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,144 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9047, pid=383
2025-07-15T14:22:54,140 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9022, pid=179
2025-07-15T14:22:54,147 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:22:54,147 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:22:54,144 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,146 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,147 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - [PID]180
2025-07-15T14:22:54,147 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,147 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]145
2025-07-15T14:22:54,147 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,146 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,148 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]148
2025-07-15T14:22:54,148 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,148 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,146 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - [PID]181
2025-07-15T14:22:54,149 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,143 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=144
2025-07-15T14:22:54,149 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:22:54,145 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:22:54,145 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:22:54,143 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9017, pid=170
2025-07-15T14:22:54,146 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - [PID]328
2025-07-15T14:22:54,146 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:22:54,144 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=165
2025-07-15T14:22:54,148 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,155 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,146 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:22:54,157 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]144
2025-07-15T14:22:54,157 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,146 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - [PID]248
2025-07-15T14:22:54,154 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,156 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,158 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,158 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,153 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,158 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,158 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - [PID]345
2025-07-15T14:22:54,154 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,158 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,154 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:22:54,158 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]143
2025-07-15T14:22:54,153 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:22:54,154 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:22:54,154 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:22:54,159 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,159 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - [PID]179
2025-07-15T14:22:54,154 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:22:54,157 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9045, pid=357
2025-07-15T14:22:54,159 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,159 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,159 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,153 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,158 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9034, pid=326
2025-07-15T14:22:54,160 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:22:54,160 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:22:54,158 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:22:54,160 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - [PID]383
2025-07-15T14:22:54,157 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9021, pid=182
2025-07-15T14:22:54,153 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,157 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:22:54,157 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,150 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,157 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:22:54,160 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,158 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - [PID]276
2025-07-15T14:22:54,160 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:22:54,158 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,154 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:22:54,161 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:22:54,159 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:22:54,154 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:22:54,158 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:22:54,153 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9030, pid=311
2025-07-15T14:22:54,150 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:22:54,161 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:22:54,159 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:22:54,153 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:22:54,162 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,159 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:22:54,154 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:22:54,161 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,162 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - [PID]170
2025-07-15T14:22:54,162 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:22:54,159 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:22:54,162 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,159 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:22:54,162 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:22:54,163 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,161 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:22:54,162 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:22:54,161 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:22:54,160 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:22:54,154 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:22:54,162 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:22:54,161 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,164 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,161 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,161 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,164 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9036, pid=329
2025-07-15T14:22:54,164 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9018, pid=171
2025-07-15T14:22:54,165 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:22:54,165 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:22:54,166 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,167 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - [PID]311
2025-07-15T14:22:54,167 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,168 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:22:54,170 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,170 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9046.
2025-07-15T14:22:54,171 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - [PID]357
2025-07-15T14:22:54,171 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,171 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,171 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,171 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:22:54,171 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,171 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:22:54,172 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - [PID]182
2025-07-15T14:22:54,172 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,172 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,172 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:22:54,173 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]165
2025-07-15T14:22:54,172 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:22:54,173 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,173 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,173 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,173 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,173 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,168 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:22:54,174 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:22:54,174 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:22:54,174 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=149
2025-07-15T14:22:54,175 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:22:54,173 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9037, pid=344
2025-07-15T14:22:54,175 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:22:54,176 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=147
2025-07-15T14:22:54,176 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9020, pid=174
2025-07-15T14:22:54,177 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:22:54,177 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:22:54,174 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374173
2025-07-15T14:22:54,174 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374173
2025-07-15T14:22:54,181 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,191 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,192 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,198 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]149
2025-07-15T14:22:54,189 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,198 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,198 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - [PID]329
2025-07-15T14:22:54,198 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,198 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,198 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,188 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,184 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9044, pid=352
2025-07-15T14:22:54,199 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]147
2025-07-15T14:22:54,199 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:22:54,199 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,199 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,199 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2025-07-15T14:22:54,183 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9016, pid=167
2025-07-15T14:22:54,199 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:22:54,189 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,199 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:22:54,199 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:22:54,199 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:22:54,200 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:22:54,200 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:22:54,182 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - [PID]326
2025-07-15T14:22:54,187 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374187
2025-07-15T14:22:54,200 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:22:54,200 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,201 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,199 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:22:54,199 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,187 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9033.
2025-07-15T14:22:54,187 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374187
2025-07-15T14:22:54,200 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:22:54,201 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - [PID]344
2025-07-15T14:22:54,202 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,198 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - [PID]171
2025-07-15T14:22:54,199 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,202 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,202 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,202 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - [PID]352
2025-07-15T14:22:54,202 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:22:54,202 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,202 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:22:54,202 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:22:54,202 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:22:54,202 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:22:54,202 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,202 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:22:54,202 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,205 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374205
2025-07-15T14:22:54,205 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374205
2025-07-15T14:22:54,205 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=154
2025-07-15T14:22:54,206 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:22:54,206 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,207 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - [PID]174
2025-07-15T14:22:54,207 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,207 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,207 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:22:54,207 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:22:54,209 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9029, pid=297
2025-07-15T14:22:54,210 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:22:54,229 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,230 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]154
2025-07-15T14:22:54,230 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,230 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,230 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:22:54,230 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:22:54,232 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,233 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - [PID]297
2025-07-15T14:22:54,233 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,233 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,233 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:22:54,233 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:22:54,234 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9024.
2025-07-15T14:22:54,234 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374234
2025-07-15T14:22:54,234 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,234 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374234
2025-07-15T14:22:54,234 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9020.
2025-07-15T14:22:54,234 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,234 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374234
2025-07-15T14:22:54,234 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374234
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - [PID]167
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:22:54,235 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:22:54,235 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=151
2025-07-15T14:22:54,236 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:22:54,241 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9027.
2025-07-15T14:22:54,241 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374241
2025-07-15T14:22:54,241 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374241
2025-07-15T14:22:54,250 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9035.
2025-07-15T14:22:54,250 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2025-07-15T14:22:54,251 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374251
2025-07-15T14:22:54,251 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374251
2025-07-15T14:22:54,253 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374253
2025-07-15T14:22:54,253 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374253
2025-07-15T14:22:54,256 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,260 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9032, pid=321
2025-07-15T14:22:54,260 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:22:54,270 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]151
2025-07-15T14:22:54,270 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,270 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,282 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,302 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - [PID]321
2025-07-15T14:22:54,302 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,302 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,661 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,702 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374702
2025-07-15T14:22:54,701 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9042.
2025-07-15T14:22:54,702 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374702
2025-07-15T14:22:54,703 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374703
2025-07-15T14:22:54,704 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374704
2025-07-15T14:22:54,701 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=336
2025-07-15T14:22:54,705 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374704
2025-07-15T14:22:54,706 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,706 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,706 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,703 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9040, pid=342
2025-07-15T14:22:54,710 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:22:54,710 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,710 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - [PID]342
2025-07-15T14:22:54,710 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9017.
2025-07-15T14:22:54,710 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,711 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,711 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:22:54,707 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9022.
2025-07-15T14:22:54,706 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9030.
2025-07-15T14:22:54,706 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,701 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9039, pid=340
2025-07-15T14:22:54,701 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:22:54,701 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:22:54,706 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,706 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374706
2025-07-15T14:22:54,711 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374711
2025-07-15T14:22:54,711 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374711
2025-07-15T14:22:54,706 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9021.
2025-07-15T14:22:54,705 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2025-07-15T14:22:54,700 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=162
2025-07-15T14:22:54,705 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374704
2025-07-15T14:22:54,712 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:22:54,712 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374712
2025-07-15T14:22:54,705 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9045.
2025-07-15T14:22:54,713 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,713 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]162
2025-07-15T14:22:54,704 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:22:54,704 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374704
2025-07-15T14:22:54,713 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,713 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:22:54,704 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2025-07-15T14:22:54,713 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]336
2025-07-15T14:22:54,714 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,700 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=157
2025-07-15T14:22:54,714 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,704 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9047.
2025-07-15T14:22:54,714 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:22:54,703 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374703
2025-07-15T14:22:54,703 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9028.
2025-07-15T14:22:54,714 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:22:54,714 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:22:54,713 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9023.
2025-07-15T14:22:54,713 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:22:54,723 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,724 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]157
2025-07-15T14:22:54,724 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:22:54,714 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,713 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,711 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:22:54,711 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:22:54,712 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374712
2025-07-15T14:22:54,724 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,724 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9032.
2025-07-15T14:22:54,725 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:54,725 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374725
2025-07-15T14:22:54,725 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - [PID]340
2025-07-15T14:22:54,726 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374725
2025-07-15T14:22:54,725 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,726 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374726
2025-07-15T14:22:54,726 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374726
2025-07-15T14:22:54,726 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:22:54,726 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:54,726 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,724 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,727 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2025-07-15T14:22:54,724 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:22:54,726 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,726 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:22:54,727 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2025-07-15T14:22:54,728 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374727
2025-07-15T14:22:54,728 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374727
2025-07-15T14:22:54,726 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374725
2025-07-15T14:22:54,728 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9036.
2025-07-15T14:22:54,728 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9034.
2025-07-15T14:22:54,728 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374728
2025-07-15T14:22:54,728 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9018.
2025-07-15T14:22:54,729 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9044.
2025-07-15T14:22:54,729 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9037.
2025-07-15T14:22:54,729 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,729 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,730 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2025-07-15T14:22:54,730 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374730
2025-07-15T14:22:54,730 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374730
2025-07-15T14:22:54,730 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374730
2025-07-15T14:22:54,730 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374730
2025-07-15T14:22:54,725 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374725
2025-07-15T14:22:54,725 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:54,729 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374729
2025-07-15T14:22:54,728 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374728
2025-07-15T14:22:54,765 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,782 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,783 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,783 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,789 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,789 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,799 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9038.
2025-07-15T14:22:54,802 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2025-07-15T14:22:54,803 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374803
2025-07-15T14:22:54,803 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374803
2025-07-15T14:22:54,809 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374809
2025-07-15T14:22:54,809 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374809
2025-07-15T14:22:54,811 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374811
2025-07-15T14:22:54,811 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374811
2025-07-15T14:22:54,812 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9040.
2025-07-15T14:22:54,850 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2025-07-15T14:22:54,851 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374851
2025-07-15T14:22:54,851 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374851
2025-07-15T14:22:54,906 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9039.
2025-07-15T14:22:54,910 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374909
2025-07-15T14:22:54,910 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374909
2025-07-15T14:22:54,920 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,922 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374921
2025-07-15T14:22:54,921 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2025-07-15T14:22:54,922 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374921
2025-07-15T14:22:54,965 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,969 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2025-07-15T14:22:54,977 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,978 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374978
2025-07-15T14:22:54,978 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374978
2025-07-15T14:22:54,978 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9029.
2025-07-15T14:22:54,978 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374978
2025-07-15T14:22:54,978 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589374978
2025-07-15T14:22:55,043 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,050 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589375050
2025-07-15T14:22:55,050 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589375050
2025-07-15T14:22:55,050 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9016.
2025-07-15T14:22:55,137 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,177 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,189 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,189 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,193 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,194 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,232 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:54,270 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:22:54,270 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:22:55,238 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,245 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,245 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,245 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,245 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,249 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,254 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,262 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2025-07-15T14:22:55,263 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589375263
2025-07-15T14:22:55,263 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,263 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589375263
2025-07-15T14:22:55,265 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,266 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,249 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,273 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,313 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,314 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,325 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,345 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:55,385 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:22:56,263 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,263 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,263 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,264 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,265 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,266 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,266 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,266 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,266 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,266 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,267 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,267 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,267 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,267 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,267 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,268 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,268 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,268 [INFO ] W-9041-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,268 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,281 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,281 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,282 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,282 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,283 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376283
2025-07-15T14:22:56,283 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376283
2025-07-15T14:22:56,284 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:22:56,284 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:22:56,290 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:22:56,290 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:22:56,291 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 1 seconds.
2025-07-15T14:22:56,291 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 1 seconds.
2025-07-15T14:22:56,324 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,325 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,326 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,327 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,328 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,329 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,330 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,330 [INFO ] W-9026-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,330 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,331 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,331 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,332 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,332 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,332 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376332
2025-07-15T14:22:56,332 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376332
2025-07-15T14:22:56,333 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:22:56,333 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:22:56,333 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:22:56,333 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:22:56,349 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,349 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,350 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,350 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,350 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,351 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,351 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376351
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376351
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,351 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,352 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:22:56,352 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:22:56,352 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:22:56,353 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:22:56,353 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:22:56,353 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 1 seconds.
2025-07-15T14:22:56,353 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 1 seconds.
2025-07-15T14:22:56,353 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 1 seconds.
2025-07-15T14:22:56,353 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 1 seconds.
2025-07-15T14:22:56,374 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:22:56,374 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:22:56,381 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:22:56,381 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:22:56,396 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:22:56,396 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:22:56,396 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:22:56,396 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:22:56,429 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:22:56,429 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:22:56,505 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,505 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,506 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,506 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,506 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,507 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,507 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376507
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376507
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,507 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,508 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:22:56,508 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:22:56,508 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:22:56,508 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-07-15T14:22:56,508 [INFO ] W-9019-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,509 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:22:56,509 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:22:56,558 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:22:56,558 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:22:56,602 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,602 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,602 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,603 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,603 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,603 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,603 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,603 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,603 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,603 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,603 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,603 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,604 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,605 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376605
2025-07-15T14:22:56,605 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376605
2025-07-15T14:22:56,606 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:22:56,606 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:22:56,606 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:22:56,606 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:22:56,606 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-07-15T14:22:56,606 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-07-15T14:22:56,607 [INFO ] W-9013-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,607 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:22:56,607 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,608 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,609 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,609 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,609 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,609 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,609 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,609 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,610 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,609 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,610 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,610 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,611 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376611
2025-07-15T14:22:56,611 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376611
2025-07-15T14:22:56,612 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:22:56,612 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:22:56,612 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:22:56,612 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:22:56,610 [INFO ] W-9025-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,612 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:22:56,612 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:22:56,613 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 1 seconds.
2025-07-15T14:22:56,613 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 1 seconds.
2025-07-15T14:22:56,658 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:22:56,658 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:22:56,660 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:22:56,660 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:22:56,667 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,667 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,667 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,668 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,668 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,669 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,669 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,669 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376669
2025-07-15T14:22:56,669 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376669
2025-07-15T14:22:56,671 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:22:56,668 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,671 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:22:56,671 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:22:56,671 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:22:56,671 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-07-15T14:22:56,671 [INFO ] W-9010-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,671 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-07-15T14:22:56,672 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:22:56,672 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:22:56,722 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:22:56,722 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:22:56,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,766 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,766 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,766 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,767 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,767 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,767 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,767 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376767
2025-07-15T14:22:56,767 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376767
2025-07-15T14:22:56,767 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,766 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,767 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,768 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,768 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,768 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,768 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,769 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,769 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,769 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,770 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:22:56,767 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,769 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,770 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,770 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,770 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:22:56,770 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,770 [INFO ] W-9000-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,770 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,770 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,771 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:22:56,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-07-15T14:22:56,771 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:22:56,771 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-07-15T14:22:56,770 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,771 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376771
2025-07-15T14:22:56,771 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376771
2025-07-15T14:22:56,772 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:22:56,772 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:22:56,772 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:22:56,772 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:22:56,772 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-07-15T14:22:56,772 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-07-15T14:22:56,771 [INFO ] W-9001-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,772 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:22:56,772 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:22:56,817 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,818 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,818 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,818 [INFO ] W-9027-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,818 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,818 [INFO ] W-9027-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,819 [INFO ] W-9027-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,819 [INFO ] W-9027-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,819 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:22:56,819 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:22:56,820 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,820 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,820 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376820
2025-07-15T14:22:56,820 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376820
2025-07-15T14:22:56,822 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:22:56,822 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:22:56,822 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:22:56,822 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:22:56,822 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 1 seconds.
2025-07-15T14:22:56,822 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 1 seconds.
2025-07-15T14:22:56,819 [INFO ] W-9027-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,822 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:22:56,822 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:22:56,838 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:22:56,838 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:22:56,842 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,842 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,842 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,842 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,842 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,842 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,842 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,843 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,843 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,843 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,843 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,843 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,843 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,843 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376844
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376844
2025-07-15T14:22:56,844 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,844 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,844 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,844 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:22:56,844 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:22:56,844 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:22:56,844 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:22:56,845 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 1 seconds.
2025-07-15T14:22:56,845 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 1 seconds.
2025-07-15T14:22:56,844 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,844 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,845 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376845
2025-07-15T14:22:56,845 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376845
2025-07-15T14:22:56,844 [INFO ] W-9043-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,844 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,846 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:22:56,846 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,846 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:22:56,846 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,846 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:22:56,846 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,846 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,846 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,846 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:22:56,848 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:22:56,848 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:22:56,847 [INFO ] W-9014-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,848 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:22:56,848 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:22:56,848 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-07-15T14:22:56,848 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-07-15T14:22:56,874 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:22:56,874 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,885 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,886 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,886 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,886 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,886 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,887 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376887
2025-07-15T14:22:56,887 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376887
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,887 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,888 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,888 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,887 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,887 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,888 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,888 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,888 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376888
2025-07-15T14:22:56,888 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376888
2025-07-15T14:22:56,889 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:22:56,889 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:22:56,890 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:22:56,890 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:22:56,890 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 1 seconds.
2025-07-15T14:22:56,890 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 1 seconds.
2025-07-15T14:22:56,886 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,888 [INFO ] W-9033-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,890 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,890 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:22:56,890 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:22:56,890 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,891 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,893 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,894 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,893 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,894 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,894 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,894 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,894 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,895 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,895 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,894 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,895 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376895
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376895
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,895 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,896 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,896 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:22:56,896 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:22:56,896 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-07-15T14:22:56,896 [INFO ] W-9018-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,899 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:22:56,899 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:22:56,899 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:22:56,899 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:22:56,899 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:22:56,899 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:22:56,899 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 1 seconds.
2025-07-15T14:22:56,899 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 1 seconds.
2025-07-15T14:22:56,916 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:22:56,916 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:22:56,918 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,918 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,918 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,919 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,919 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,919 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,920 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,920 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376920
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376920
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,920 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,921 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:22:56,921 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:22:56,921 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:22:56,921 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:22:56,921 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-07-15T14:22:56,921 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-07-15T14:22:56,923 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:22:56,923 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:22:56,933 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,933 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,933 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,934 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,934 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,934 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,934 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376935
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376935
2025-07-15T14:22:56,934 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,935 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:22:56,935 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,935 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:22:56,936 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:22:56,936 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:22:56,936 [INFO ] W-9032-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,936 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 1 seconds.
2025-07-15T14:22:56,936 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 1 seconds.
2025-07-15T14:22:56,936 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:22:56,936 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:22:56,942 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:22:56,942 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:22:56,942 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:22:56,942 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:22:56,949 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:22:56,949 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,950 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,951 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,951 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,951 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,951 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376951
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376951
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,951 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,952 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:22:56,952 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:22:56,952 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:22:56,952 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:22:56,952 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,961 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,961 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,961 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,962 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,962 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376962
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376962
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,962 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,963 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:22:56,963 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:22:56,963 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,963 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-07-15T14:22:56,963 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:22:56,964 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:22:56,964 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:22:56,975 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,976 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,976 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,976 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,977 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,977 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376977
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376977
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,977 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:56,978 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:56,979 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:22:56,979 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:22:56,979 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:22:56,979 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:22:56,979 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 1 seconds.
2025-07-15T14:22:56,979 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:22:56,979 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 1 seconds.
2025-07-15T14:22:56,979 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:22:56,979 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:22:56,979 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:56,982 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:56,982 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:56,982 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:56,983 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:56,983 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376983
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589376983
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:56,983 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:56,983 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:22:56,983 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:56,984 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:56,984 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 1 seconds.
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:22:56,984 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 1 seconds.
2025-07-15T14:22:56,992 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:22:56,992 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:22:57,013 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:22:57,013 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:22:57,019 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:22:57,019 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:22:57,028 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:22:57,028 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:22:57,028 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:22:57,028 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,030 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,030 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,030 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,031 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,031 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377031
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377031
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,031 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,032 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:57,032 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:22:57,032 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:22:57,032 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 1 seconds.
2025-07-15T14:22:57,032 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 1 seconds.
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,033 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,033 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,033 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,034 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,034 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377034
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377034
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,035 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:22:57,034 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,035 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,035 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:22:57,035 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:22:57,035 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-07-15T14:22:57,035 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:22:57,035 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,037 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,038 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,038 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,038 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,038 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377038
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377038
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,038 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,039 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:22:57,039 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:22:57,039 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,040 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:22:57,040 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:22:57,040 [INFO ] W-9036-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:57,040 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:22:57,040 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:22:57,040 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 1 seconds.
2025-07-15T14:22:57,040 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 1 seconds.
2025-07-15T14:22:57,052 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,052 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,052 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,052 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,052 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,052 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,052 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,053 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,053 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377053
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,053 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377053
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,054 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,054 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:22:57,054 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:57,054 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 1 seconds.
2025-07-15T14:22:57,054 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 1 seconds.
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,057 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,058 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,058 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,058 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,058 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377058
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377058
2025-07-15T14:22:57,058 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,059 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:22:57,059 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:22:57,059 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:22:57,059 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 1 seconds.
2025-07-15T14:22:57,059 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 1 seconds.
2025-07-15T14:22:57,060 [INFO ] W-9023-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,060 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:22:57,060 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,077 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,077 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,077 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,078 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,078 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377078
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377078
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,078 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:57,079 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:22:57,079 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:22:57,079 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:22:57,079 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-07-15T14:22:57,079 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,081 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,081 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,081 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,082 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,082 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377082
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377082
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,082 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     from graphcast import rollout
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/rollout.py", line 21, in <module>
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     from graphcast import xarray_jax
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/graphcast/xarray_jax.py", line 1007, in <module>
2025-07-15T14:22:57,083 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout MODEL_LOG -     def _flatten_datatree(datatree: xarray.DataTree) -> Tuple[
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - AttributeError: module 'xarray' has no attribute 'DataTree'
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:22:57,083 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:22:57,083 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:22:57,083 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 1 seconds.
2025-07-15T14:22:57,083 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 1 seconds.
2025-07-15T14:22:57,087 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:22:57,087 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:22:57,092 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:22:57,092 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:22:57,102 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:22:57,102 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:22:57,132 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,132 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,133 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,133 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,132 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,133 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,133 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,135 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,134 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,135 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,136 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,132 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:22:57,134 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,139 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,139 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,139 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377139
2025-07-15T14:22:57,132 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,137 [INFO ] W-9038-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,134 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:22:57,135 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,137 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,139 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,140 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377140
2025-07-15T14:22:57,137 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,135 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,140 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,139 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377139
2025-07-15T14:22:57,140 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,140 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,137 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,144 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:22:57,141 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,145 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377145
2025-07-15T14:22:57,137 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,141 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,144 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:22:57,134 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:22:57,146 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377146
2025-07-15T14:22:57,140 [INFO ] W-9006-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,145 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,140 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377140
2025-07-15T14:22:57,145 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377145
2025-07-15T14:22:57,145 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,145 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377145
2025-07-15T14:22:57,149 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:22:57,149 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:22:57,142 [INFO ] W-9038-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,144 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,149 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:22:57,144 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,141 [INFO ] W-9045-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,141 [INFO ] W-9009-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,149 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:22:57,139 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,149 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,151 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,147 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:22:57,145 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,151 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,147 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:22:57,151 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,151 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 1 seconds.
2025-07-15T14:22:57,151 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 1 seconds.
2025-07-15T14:22:57,151 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,146 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377146
2025-07-15T14:22:57,149 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,151 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,152 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377152
2025-07-15T14:22:57,152 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,152 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377152
2025-07-15T14:22:57,152 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,152 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:22:57,152 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:22:57,152 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:22:57,152 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:22:57,152 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 1 seconds.
2025-07-15T14:22:57,151 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:22:57,152 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,153 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:22:57,153 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:22:57,151 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,145 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377145
2025-07-15T14:22:57,151 [INFO ] W-9038-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,151 [INFO ] W-9009-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,153 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:22:57,151 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,153 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:22:57,153 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:22:57,153 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:22:57,154 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:22:57,152 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 1 seconds.
2025-07-15T14:22:57,154 [INFO ] W-9011-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,154 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:22:57,154 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-07-15T14:22:57,151 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:22:57,154 [INFO ] W-9011-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,154 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-07-15T14:22:57,153 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377153
2025-07-15T14:22:57,154 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-07-15T14:22:57,154 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,154 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-07-15T14:22:57,153 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377153
2025-07-15T14:22:57,150 [INFO ] W-9006-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,155 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:22:57,155 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,155 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:22:57,155 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:22:57,155 [INFO ] W-9009-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,155 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:22:57,156 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,156 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:22:57,156 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:22:57,155 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:22:57,156 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:22:57,156 [INFO ] W-9009-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,156 [INFO ] W-9015-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,155 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:22:57,156 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-07-15T14:22:57,156 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:22:57,156 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-07-15T14:22:57,156 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,157 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:22:57,156 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-07-15T14:22:57,157 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:22:57,156 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-07-15T14:22:57,157 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 1 seconds.
2025-07-15T14:22:57,157 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 1 seconds.
2025-07-15T14:22:57,165 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:22:57,165 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:22:57,166 [INFO ] W-9039-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,165 [INFO ] W-9009-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,169 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:22:57,169 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:22:57,170 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:22:57,155 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:22:57,170 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:22:57,155 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:22:57,171 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,172 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,172 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,175 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,175 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,176 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377176
2025-07-15T14:22:57,175 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,176 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377176
2025-07-15T14:22:57,176 [INFO ] W-9044-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,176 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:22:57,176 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:22:57,177 [INFO ] W-9044-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,177 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:22:57,177 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:22:57,177 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 1 seconds.
2025-07-15T14:22:57,177 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 1 seconds.
2025-07-15T14:22:57,178 [INFO ] W-9044-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,178 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:22:57,178 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:22:57,178 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,179 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,179 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,179 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,179 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,183 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,183 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,183 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,184 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,184 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,184 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377184
2025-07-15T14:22:57,184 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377184
2025-07-15T14:22:57,184 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,185 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:22:57,185 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:22:57,185 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,185 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,186 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:22:57,186 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,186 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:22:57,186 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 1 seconds.
2025-07-15T14:22:57,186 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 1 seconds.
2025-07-15T14:22:57,186 [INFO ] W-9028-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,187 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:22:57,187 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:22:57,192 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,192 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,192 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,193 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,193 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,193 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,194 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,194 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,194 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,193 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,194 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,194 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,194 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,194 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,194 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,194 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377194
2025-07-15T14:22:57,194 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377194
2025-07-15T14:22:57,193 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,195 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:22:57,195 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,195 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,195 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:22:57,195 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:22:57,195 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:22:57,195 [INFO ] W-9002-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,196 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:22:57,196 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-07-15T14:22:57,195 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,195 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,196 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-07-15T14:22:57,196 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,196 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,196 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:22:57,196 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,196 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,196 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377196
2025-07-15T14:22:57,196 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,196 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377196
2025-07-15T14:22:57,197 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:22:57,197 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:22:57,197 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:22:57,197 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:22:57,197 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 1 seconds.
2025-07-15T14:22:57,197 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 1 seconds.
2025-07-15T14:22:57,198 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,201 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,201 [INFO ] W-9029-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,201 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,201 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:22:57,201 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:22:57,201 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,201 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,202 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,203 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,203 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,202 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,203 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,203 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,203 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,202 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,204 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,204 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,204 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,204 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,204 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,204 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,205 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377205
2025-07-15T14:22:57,205 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,204 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,205 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377205
2025-07-15T14:22:57,205 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377205
2025-07-15T14:22:57,205 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,205 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377205
2025-07-15T14:22:57,205 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,205 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,205 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,206 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:22:57,206 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:22:57,206 [INFO ] W-9030-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,206 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:22:57,206 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:22:57,206 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:22:57,206 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 1 seconds.
2025-07-15T14:22:57,206 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 1 seconds.
2025-07-15T14:22:57,205 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,206 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:22:57,206 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:22:57,206 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:22:57,207 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 1 seconds.
2025-07-15T14:22:57,207 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 1 seconds.
2025-07-15T14:22:57,207 [INFO ] W-9021-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,207 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:22:57,207 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:22:57,208 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:22:57,208 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:22:57,211 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:22:57,211 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:22:57,212 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:22:57,212 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:22:57,219 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:22:57,219 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:22:57,234 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,234 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,234 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,234 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,234 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,234 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,236 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,235 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,236 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377236
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377236
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,236 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,237 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,236 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:22:57,237 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:22:57,237 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:22:57,238 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,236 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:22:57,238 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 1 seconds.
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 1 seconds.
2025-07-15T14:22:57,238 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:22:57,243 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:22:57,243 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:22:57,249 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,249 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,249 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,250 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,250 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,250 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,250 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,250 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,250 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,250 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,250 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,250 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,250 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,250 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,250 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,251 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,251 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,251 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377251
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,251 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,251 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,251 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377251
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377251
2025-07-15T14:22:57,251 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377251
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,251 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,251 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,252 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,252 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,252 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,252 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,252 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:22:57,253 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,253 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:22:57,253 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:22:57,252 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:22:57,253 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:22:57,253 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 1 seconds.
2025-07-15T14:22:57,253 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 1 seconds.
2025-07-15T14:22:57,251 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:22:57,253 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:22:57,253 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:22:57,253 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:22:57,253 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-07-15T14:22:57,251 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:22:57,271 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:22:57,271 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:22:57,288 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:22:57,288 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:22:57,299 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:22:57,299 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:22:57,302 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,302 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,302 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,302 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,302 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,303 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,303 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377303
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377303
2025-07-15T14:22:57,303 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,304 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,304 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,304 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,304 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,304 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:22:57,304 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,305 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,305 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,305 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,305 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:22:57,305 [INFO ] W-9040-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,306 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 1 seconds.
2025-07-15T14:22:57,306 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 1 seconds.
2025-07-15T14:22:57,306 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:22:57,306 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:22:57,308 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:22:57,308 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:22:57,308 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:22:57,308 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:22:57,310 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:22:57,310 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:22:57,313 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,313 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,313 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,313 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,313 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,313 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,314 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,314 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377314
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377314
2025-07-15T14:22:57,314 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,316 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,316 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:22:57,316 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,316 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:22:57,316 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:22:57,317 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-07-15T14:22:57,317 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-07-15T14:22:57,317 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:22:57,317 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:22:57,322 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:22:57,322 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,327 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,327 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,327 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,327 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,327 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377327
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377327
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,328 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:22:57,328 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:22:57,328 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:22:57,328 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:22:57,328 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:22:57,329 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 1 seconds.
2025-07-15T14:22:57,329 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 1 seconds.
2025-07-15T14:22:57,349 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:22:57,349 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Backend worker process died.
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 253, in <module>
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     worker.run_server()
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 221, in run_server
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_service_worker.py", line 131, in load_model
2025-07-15T14:22:57,359 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     service = model_loader.load(
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/ts/model_loader.py", line 135, in load
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_pytorch_serving_container/handler_service.py", line 51, in initialize
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     super().initialize(context)
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/default_handler_service.py", line 66, in initialize
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     self._service.validate_and_initialize(model_dir=model_dir, context=context)
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 179, in validate_and_initialize
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     self._validate_user_module_and_set_functions()
2025-07-15T14:22:57,360 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/site-packages/sagemaker_inference/transformer.py", line 206, in _validate_user_module_and_set_functions
2025-07-15T14:22:57,360 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     user_module = importlib.import_module(user_module_name)
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/conda/lib/python3.10/importlib/__init__.py", line 126, in import_module
2025-07-15T14:22:57,360 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2025-07-15T14:22:57,360 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: model, error: Worker died.
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377360
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1752589377360
2025-07-15T14:22:57,360 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 883, in exec_module
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/inference.py", line 3, in <module>
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -     from resources import gencast_predict
2025-07-15T14:22:57,361 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:22:57,361 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:22:57,361 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:22:57,361 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:22:57,361 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-07-15T14:22:57,361 [INFO ] W-9012-model_1.0-stdout MODEL_LOG -   File "/opt/ml/model/resources.py", line 20, in <module>
2025-07-15T14:22:57,362 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:22:57,362 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:22:57,361 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:22:57,373 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:22:57,373 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:22:57,401 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:22:57,401 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:22:59,192 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9026, pid=5268
2025-07-15T14:22:59,193 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:59,204 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:59,205 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - [PID]5268
2025-07-15T14:22:59,209 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:59,209 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:59,209 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:22:59,210 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:59,233 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,233 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,233 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,233 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9026.
2025-07-15T14:22:59,233 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,234 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:22:59,234 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:22:59,234 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:22:59,234 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:22:59,234 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 1 seconds.
2025-07-15T14:22:59,234 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 1 seconds.
2025-07-15T14:22:59,336 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=5265
2025-07-15T14:22:59,337 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:59,355 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:59,355 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]5265
2025-07-15T14:22:59,356 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:59,356 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:59,356 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:22:59,357 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:59,375 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9041.
2025-07-15T14:22:59,376 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,376 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,378 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,378 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,379 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:22:59,379 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:22:59,379 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:22:59,379 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:22:59,379 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 1 seconds.
2025-07-15T14:22:59,379 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 1 seconds.
2025-07-15T14:22:59,429 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=5271
2025-07-15T14:22:59,430 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:59,444 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:22:59,444 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]5271
2025-07-15T14:22:59,445 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:59,444 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:22:59,445 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:22:59,445 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:22:59,496 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9031.
2025-07-15T14:22:59,497 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,497 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:22:59,497 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,497 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:22:59,498 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:22:59,498 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:22:59,499 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:22:59,499 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:22:59,499 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 1 seconds.
2025-07-15T14:22:59,499 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 1 seconds.
2025-07-15T14:23:00,113 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=5274
2025-07-15T14:23:00,114 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:00,128 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,129 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]5274
2025-07-15T14:23:00,131 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:00,130 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,131 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:00,131 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,150 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,150 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,151 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,151 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,150 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:23:00,153 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:00,153 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:00,153 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:00,153 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:00,154 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-07-15T14:23:00,154 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 1 seconds.
2025-07-15T14:23:00,197 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:00,197 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:00,198 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:00,198 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:00,212 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=5277
2025-07-15T14:23:00,213 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:00,227 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,228 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]5277
2025-07-15T14:23:00,228 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:00,228 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,228 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:00,230 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,232 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,232 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,233 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,233 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,234 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:23:00,234 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:00,234 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:00,236 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:00,236 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:00,236 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-07-15T14:23:00,236 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 1 seconds.
2025-07-15T14:23:00,268 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:00,268 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:00,268 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:00,268 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:00,306 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=5280
2025-07-15T14:23:00,306 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:00,320 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,321 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]5280
2025-07-15T14:23:00,321 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,321 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:00,321 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,321 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:00,324 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9025.
2025-07-15T14:23:00,325 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,325 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,325 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,325 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,326 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:00,326 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:00,326 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:00,326 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:00,326 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 1 seconds.
2025-07-15T14:23:00,326 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 1 seconds.
2025-07-15T14:23:00,331 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=5283
2025-07-15T14:23:00,332 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:00,344 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,344 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]5283
2025-07-15T14:23:00,345 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,345 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:00,345 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,345 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:00,361 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9016, pid=5472
2025-07-15T14:23:00,361 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:00,362 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:23:00,363 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,363 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,363 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,363 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,364 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:00,364 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:00,364 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:00,364 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:00,364 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-07-15T14:23:00,364 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 1 seconds.
2025-07-15T14:23:00,367 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:00,367 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:00,367 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:00,367 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:00,368 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:00,368 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:00,368 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:00,368 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:00,371 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:00,371 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:00,371 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:00,371 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - [PID]5472
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,375 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:00,368 [ERROR] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker error
org.pytorch.serve.wlm.WorkerInitializationException: Backend stream closed.
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:173) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:339) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2025-07-15T14:23:00,368 [ERROR] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker error
org.pytorch.serve.wlm.WorkerInitializationException: Backend stream closed.
	at org.pytorch.serve.wlm.WorkerLifeCycle.startWorker(WorkerLifeCycle.java:173) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:339) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2025-07-15T14:23:00,410 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,417 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=5286
2025-07-15T14:23:00,417 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:00,410 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,417 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,418 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:00,417 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,418 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:00,418 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:00,418 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9016.
2025-07-15T14:23:00,418 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:00,418 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,418 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 2 seconds.
2025-07-15T14:23:00,418 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,419 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:00,419 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:00,419 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:00,419 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:00,419 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-07-15T14:23:00,419 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 1 seconds.
2025-07-15T14:23:00,418 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 2 seconds.
2025-07-15T14:23:00,424 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9017, pid=5453
2025-07-15T14:23:00,424 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:00,431 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,431 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]5286
2025-07-15T14:23:00,431 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,431 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:00,432 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:00,435 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9043, pid=5295
2025-07-15T14:23:00,437 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:00,439 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,439 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - [PID]5453
2025-07-15T14:23:00,439 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,440 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:00,440 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,440 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:00,440 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=5491
2025-07-15T14:23:00,441 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:00,441 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,441 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,442 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:23:00,442 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,442 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,442 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:00,442 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:00,443 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:00,443 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:00,443 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-07-15T14:23:00,443 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2025-07-15T14:23:00,450 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,450 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - [PID]5295
2025-07-15T14:23:00,450 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,451 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:00,451 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:00,451 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,456 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,456 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9017.
2025-07-15T14:23:00,456 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]5491
2025-07-15T14:23:00,456 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,457 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,467 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:00,467 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:00,467 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,467 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,468 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,468 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,468 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:00,468 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:00,469 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:00,469 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:00,469 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,469 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9043.
2025-07-15T14:23:00,469 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-07-15T14:23:00,469 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,469 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,469 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,470 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:00,470 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:00,470 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:00,470 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:00,470 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 1 seconds.
2025-07-15T14:23:00,470 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 1 seconds.
2025-07-15T14:23:00,475 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,475 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,475 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9038.
2025-07-15T14:23:00,475 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,475 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,476 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:00,476 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:00,476 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:00,476 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:00,476 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 1 seconds.
2025-07-15T14:23:00,476 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 1 seconds.
2025-07-15T14:23:00,469 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 1 seconds.
2025-07-15T14:23:00,497 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9037, pid=5463
2025-07-15T14:23:00,498 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - [PID]5463
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:00,512 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:00,524 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9037.
2025-07-15T14:23:00,524 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,524 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:00,525 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:00,525 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 1 seconds.
2025-07-15T14:23:00,525 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 1 seconds.
2025-07-15T14:23:00,556 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=5288
2025-07-15T14:23:00,557 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:00,564 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=5499
2025-07-15T14:23:00,565 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]5288
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,571 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:00,578 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,579 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]5499
2025-07-15T14:23:00,579 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,579 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,579 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:00,579 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:00,581 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,581 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,581 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2025-07-15T14:23:00,581 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,581 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,582 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:00,582 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:00,582 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:00,582 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:00,582 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-07-15T14:23:00,582 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2025-07-15T14:23:00,593 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=5484
2025-07-15T14:23:00,594 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:00,601 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,602 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]5484
2025-07-15T14:23:00,602 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,602 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,602 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,602 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2025-07-15T14:23:00,602 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,602 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:00,602 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:00,602 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,602 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,603 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:00,603 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:00,603 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:00,603 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:00,614 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-07-15T14:23:00,613 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9023, pid=5481
2025-07-15T14:23:00,614 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:00,614 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 1 seconds.
2025-07-15T14:23:00,606 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9032, pid=5450
2025-07-15T14:23:00,615 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:00,604 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=5445
2025-07-15T14:23:00,615 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:00,614 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9042, pid=5469
2025-07-15T14:23:00,618 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:00,620 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,621 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - [PID]5450
2025-07-15T14:23:00,621 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,621 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,621 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:00,621 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:00,623 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9032.
2025-07-15T14:23:00,624 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,624 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,624 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,624 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,625 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:00,625 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:00,625 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:00,625 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:00,626 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 1 seconds.
2025-07-15T14:23:00,626 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 1 seconds.
2025-07-15T14:23:00,627 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,628 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - [PID]5481
2025-07-15T14:23:00,628 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,628 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,628 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:00,628 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:00,628 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,629 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - [PID]5469
2025-07-15T14:23:00,629 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,629 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,629 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:00,629 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:00,630 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,630 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,630 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2025-07-15T14:23:00,630 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,630 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,631 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:00,631 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:00,631 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:00,631 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:00,631 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-07-15T14:23:00,631 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2025-07-15T14:23:00,632 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,633 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - [PID]5445
2025-07-15T14:23:00,633 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,633 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:00,633 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:00,633 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,635 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9023.
2025-07-15T14:23:00,635 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,635 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:00,636 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:00,636 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 1 seconds.
2025-07-15T14:23:00,636 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 1 seconds.
2025-07-15T14:23:00,642 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=5460
2025-07-15T14:23:00,646 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:00,655 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,656 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]5460
2025-07-15T14:23:00,669 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,670 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:00,669 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,670 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:00,669 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9027, pid=5292
2025-07-15T14:23:00,670 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:00,671 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9042.
2025-07-15T14:23:00,673 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,673 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:00,674 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:00,675 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 1 seconds.
2025-07-15T14:23:00,675 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 1 seconds.
2025-07-15T14:23:00,669 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=5448
2025-07-15T14:23:00,677 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:00,678 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,678 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]5448
2025-07-15T14:23:00,678 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,678 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,678 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,682 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9033, pid=5442
2025-07-15T14:23:00,682 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:00,685 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:00,685 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:00,686 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - [PID]5292
2025-07-15T14:23:00,686 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,686 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,687 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:00,687 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:00,690 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=5298
2025-07-15T14:23:00,691 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:00,695 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,696 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9036, pid=5475
2025-07-15T14:23:00,697 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:00,699 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9024, pid=5478
2025-07-15T14:23:00,699 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:00,701 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2025-07-15T14:23:00,703 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,703 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,703 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,703 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,704 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:00,704 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:00,704 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:00,704 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:00,704 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-07-15T14:23:00,704 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2025-07-15T14:23:00,705 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,705 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,705 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9046.
2025-07-15T14:23:00,705 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,705 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,706 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:00,706 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:00,706 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:00,706 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:00,706 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 1 seconds.
2025-07-15T14:23:00,706 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 1 seconds.
2025-07-15T14:23:00,711 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,711 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]5298
2025-07-15T14:23:00,711 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,711 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,714 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2025-07-15T14:23:00,715 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,715 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:00,716 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:00,716 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-07-15T14:23:00,716 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2025-07-15T14:23:00,719 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,720 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - [PID]5475
2025-07-15T14:23:00,720 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,720 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,720 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:00,720 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - [PID]5478
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:00,726 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:00,729 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:00,729 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:00,730 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - [PID]5442
2025-07-15T14:23:00,730 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,730 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,730 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,730 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,730 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,730 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:00,730 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9027.
2025-07-15T14:23:00,730 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:00,730 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:00,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:00,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:00,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:00,731 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 1 seconds.
2025-07-15T14:23:00,731 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 1 seconds.
2025-07-15T14:23:00,736 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9018, pid=5444
2025-07-15T14:23:00,736 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:00,737 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9036.
2025-07-15T14:23:00,737 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,737 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,737 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,737 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,738 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:00,738 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:00,738 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:00,738 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:00,738 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 1 seconds.
2025-07-15T14:23:00,738 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 1 seconds.
2025-07-15T14:23:00,749 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,750 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - [PID]5444
2025-07-15T14:23:00,750 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,750 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,751 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:00,751 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:00,754 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,754 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,755 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2025-07-15T14:23:00,755 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,755 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,756 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:00,756 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:00,756 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:00,756 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:00,756 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-07-15T14:23:00,756 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 1 seconds.
2025-07-15T14:23:00,771 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9022, pid=5466
2025-07-15T14:23:00,771 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:00,778 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,778 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9024.
2025-07-15T14:23:00,778 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,780 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9033.
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,781 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,781 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:00,781 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:00,781 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 1 seconds.
2025-07-15T14:23:00,781 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 1 seconds.
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:00,781 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:00,782 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 1 seconds.
2025-07-15T14:23:00,782 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 1 seconds.
2025-07-15T14:23:00,785 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,786 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - [PID]5466
2025-07-15T14:23:00,785 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=5498
2025-07-15T14:23:00,787 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:00,789 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,789 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,789 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:00,789 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:00,790 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9018.
2025-07-15T14:23:00,790 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,790 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,790 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,790 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,791 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:00,791 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:00,791 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:00,791 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:00,791 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-07-15T14:23:00,791 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 1 seconds.
2025-07-15T14:23:00,798 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,809 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]5498
2025-07-15T14:23:00,809 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,810 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,810 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:00,810 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:00,817 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,817 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,825 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9022.
2025-07-15T14:23:00,828 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,828 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,829 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:00,829 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:00,829 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:00,829 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:00,829 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 1 seconds.
2025-07-15T14:23:00,829 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 1 seconds.
2025-07-15T14:23:00,842 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2025-07-15T14:23:00,849 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=5496
2025-07-15T14:23:00,850 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:00,850 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9040, pid=5679
2025-07-15T14:23:00,850 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:00,856 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,856 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,856 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,857 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,857 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,857 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]5496
2025-07-15T14:23:00,858 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:00,858 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:00,857 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,858 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:00,858 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:00,858 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:00,858 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:00,858 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-07-15T14:23:00,858 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 1 seconds.
2025-07-15T14:23:00,858 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,862 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9020, pid=5487
2025-07-15T14:23:00,862 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:00,864 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,865 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - [PID]5679
2025-07-15T14:23:00,865 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,865 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:00,865 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,865 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:00,870 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9044, pid=5511
2025-07-15T14:23:00,871 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:00,873 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,874 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - [PID]5487
2025-07-15T14:23:00,874 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,874 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,874 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:00,874 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:00,879 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,884 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - [PID]5511
2025-07-15T14:23:00,885 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:00,884 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,885 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,885 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:00,882 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9039, pid=5501
2025-07-15T14:23:00,892 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:00,893 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2025-07-15T14:23:00,894 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,894 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,894 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9040.
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - [PID]5501
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:00,895 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:00,895 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 1 seconds.
2025-07-15T14:23:00,895 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 1 seconds.
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:00,895 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:00,896 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,896 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,896 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,896 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,897 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:00,897 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:00,897 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:00,897 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:00,897 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-07-15T14:23:00,897 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2025-07-15T14:23:00,904 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,904 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,904 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9020.
2025-07-15T14:23:00,904 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,904 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,905 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:00,905 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:00,905 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:00,905 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:00,905 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 1 seconds.
2025-07-15T14:23:00,905 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 1 seconds.
2025-07-15T14:23:00,909 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9044.
2025-07-15T14:23:00,909 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,909 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:00,910 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:00,910 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 1 seconds.
2025-07-15T14:23:00,910 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 1 seconds.
2025-07-15T14:23:00,936 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9039.
2025-07-15T14:23:00,937 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,937 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:00,937 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:00,938 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 1 seconds.
2025-07-15T14:23:00,938 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 1 seconds.
2025-07-15T14:23:00,940 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=5624
2025-07-15T14:23:00,942 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:00,950 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:00,950 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:00,950 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:00,950 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:00,953 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,954 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]5624
2025-07-15T14:23:00,954 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,954 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,954 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:00,954 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:00,964 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9021, pid=5524
2025-07-15T14:23:00,965 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:00,970 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9035, pid=5682
2025-07-15T14:23:00,971 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:00,972 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9045, pid=5490
2025-07-15T14:23:00,973 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:00,977 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2025-07-15T14:23:00,977 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,977 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:00,978 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:00,978 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-07-15T14:23:00,978 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 1 seconds.
2025-07-15T14:23:00,981 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,981 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=5517
2025-07-15T14:23:00,981 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:00,981 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - [PID]5524
2025-07-15T14:23:00,981 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,982 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:00,982 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,982 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:00,984 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,985 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - [PID]5682
2025-07-15T14:23:00,985 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,985 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:00,985 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:00,985 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,987 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,987 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - [PID]5490
2025-07-15T14:23:00,987 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,987 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:00,987 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:00,988 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,992 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=5495
2025-07-15T14:23:00,992 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:00,996 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:00,996 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9030, pid=5523
2025-07-15T14:23:00,996 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:00,996 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]5517
2025-07-15T14:23:00,997 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:00,996 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:00,997 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:00,997 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:01,002 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,002 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,002 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,002 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,003 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:01,003 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:01,002 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9021.
2025-07-15T14:23:01,005 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:01,005 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:01,005 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 1 seconds.
2025-07-15T14:23:01,005 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 1 seconds.
2025-07-15T14:23:01,005 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:01,005 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:01,007 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,007 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]5495
2025-07-15T14:23:01,007 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,008 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:01,008 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,008 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:01,011 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,012 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - [PID]5523
2025-07-15T14:23:01,012 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,012 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:01,012 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,012 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:01,015 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,015 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9035.
2025-07-15T14:23:01,015 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,016 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,016 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,017 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:01,017 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:01,017 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:01,017 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:01,017 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 1 seconds.
2025-07-15T14:23:01,017 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 1 seconds.
2025-07-15T14:23:01,020 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:01,020 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:01,020 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:01,020 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:01,025 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=5680
2025-07-15T14:23:01,025 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:01,027 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9045.
2025-07-15T14:23:01,027 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,027 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,027 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,027 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,028 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:01,028 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:01,028 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:01,028 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:01,028 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 1 seconds.
2025-07-15T14:23:01,028 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 1 seconds.
2025-07-15T14:23:01,036 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,036 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,036 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9030.
2025-07-15T14:23:01,036 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,036 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,037 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:01,037 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:01,037 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:01,037 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:01,037 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 1 seconds.
2025-07-15T14:23:01,037 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 1 seconds.
2025-07-15T14:23:01,040 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,040 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,041 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2025-07-15T14:23:01,041 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,041 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,041 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2025-07-15T14:23:01,041 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,041 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9028, pid=5514
2025-07-15T14:23:01,041 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,041 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:01,041 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:01,041 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:01,041 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-07-15T14:23:01,041 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:01,041 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2025-07-15T14:23:01,042 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:01,042 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:01,042 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-07-15T14:23:01,042 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 1 seconds.
2025-07-15T14:23:01,047 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,047 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]5680
2025-07-15T14:23:01,048 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,048 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,048 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:01,048 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:01,052 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,052 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,052 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:01,052 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:01,053 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-07-15T14:23:01,053 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2025-07-15T14:23:01,063 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,063 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=5735
2025-07-15T14:23:01,070 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:01,070 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9034, pid=5625
2025-07-15T14:23:01,070 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:01,071 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - [PID]5514
2025-07-15T14:23:01,071 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,071 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:01,071 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:01,072 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,075 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,075 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]5735
2025-07-15T14:23:01,075 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,076 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,076 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:01,076 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:01,090 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,092 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,092 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,092 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9028.
2025-07-15T14:23:01,092 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - [PID]5625
2025-07-15T14:23:01,093 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:01,092 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,093 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,093 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:01,094 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,094 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,094 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:01,094 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:01,095 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:01,095 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:01,095 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 1 seconds.
2025-07-15T14:23:01,095 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 1 seconds.
2025-07-15T14:23:01,102 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9047, pid=5623
2025-07-15T14:23:01,102 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:01,103 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2025-07-15T14:23:01,103 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,103 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,103 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,103 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,104 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:01,104 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:01,104 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:01,104 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:01,104 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-07-15T14:23:01,104 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 1 seconds.
2025-07-15T14:23:01,108 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,108 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,108 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9034.
2025-07-15T14:23:01,108 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,108 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,109 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:01,109 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:01,109 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:01,109 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:01,109 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 1 seconds.
2025-07-15T14:23:01,109 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 1 seconds.
2025-07-15T14:23:01,109 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9029, pid=5518
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,110 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - [PID]5623
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,110 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:01,123 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:01,124 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - [PID]5518
2025-07-15T14:23:01,124 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:01,124 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:01,124 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:01,124 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:01,140 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,140 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,141 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,141 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,141 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9047.
2025-07-15T14:23:01,142 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:01,142 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:01,142 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:01,142 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:01,142 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 1 seconds.
2025-07-15T14:23:01,142 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 1 seconds.
2025-07-15T14:23:01,162 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:01,162 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:01,163 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:01,163 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:01,164 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:01,164 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:01,164 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:01,165 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,165 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:01,164 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:01,165 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,165 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:01,166 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:01,166 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:01,166 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:01,166 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:01,166 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 1 seconds.
2025-07-15T14:23:01,166 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 1 seconds.
2025-07-15T14:23:01,292 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:01,292 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:01,292 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:01,292 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:01,302 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:01,302 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:01,302 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:01,302 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:01,315 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:01,315 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:01,315 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:01,315 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:01,339 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:01,339 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:01,339 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:01,339 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:01,348 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:01,348 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:01,348 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:01,348 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:01,358 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:01,358 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:01,358 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:01,358 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:01,423 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:01,423 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:01,423 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:01,423 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:01,445 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:01,445 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:01,445 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:01,445 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:01,460 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:01,460 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:01,460 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:01,460 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:01,482 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:01,482 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:01,482 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:01,482 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:01,486 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:01,486 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:01,486 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:01,486 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:01,486 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:01,486 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:01,486 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:01,486 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:01,507 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:01,507 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:01,507 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:01,507 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:01,508 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:01,508 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:01,508 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:01,508 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:01,508 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:01,508 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:01,508 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:01,508 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:01,523 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:01,523 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:01,523 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:01,523 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:01,524 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:01,524 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:01,524 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:01,524 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:01,527 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:01,527 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:01,527 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:01,527 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:01,533 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:01,533 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:01,533 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:01,533 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:01,534 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:01,534 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:01,534 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:01,534 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:01,550 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:01,550 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:01,550 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:01,550 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:01,554 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:01,554 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:01,554 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:01,554 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:01,567 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:01,567 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:01,567 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:01,567 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:01,587 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:01,587 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:01,587 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:01,587 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:01,618 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:01,618 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:01,618 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:01,618 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:01,633 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:01,633 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:01,634 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:01,634 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:01,648 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:01,648 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:01,648 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:01,648 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:01,668 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:01,668 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:01,668 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:01,668 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:01,669 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:01,669 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:01,669 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:01,669 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:01,678 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:01,678 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:01,678 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:01,678 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:01,678 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:01,678 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:01,681 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:01,681 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:01,681 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:01,681 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:01,716 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:01,716 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:01,717 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:01,717 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:01,749 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:01,749 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:01,749 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:01,749 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:01,756 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:01,755 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:01,756 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:01,755 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:01,761 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:01,761 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:01,761 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:01,761 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:01,771 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:01,771 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:01,771 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:01,771 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:01,786 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:01,786 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:01,786 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:01,786 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:01,794 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:01,794 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:01,794 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:01,794 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:01,809 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:01,809 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:01,809 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:01,809 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:01,812 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:01,812 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:01,812 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:01,812 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:02,989 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=7736
2025-07-15T14:23:02,990 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:03,037 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=7708
2025-07-15T14:23:03,037 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:03,045 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,046 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]7708
2025-07-15T14:23:03,046 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:03,046 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,046 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:03,047 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,047 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,047 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,048 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,048 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,049 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:03,049 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:03,049 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:03,049 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:03,049 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 2 seconds.
2025-07-15T14:23:03,049 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 2 seconds.
2025-07-15T14:23:03,054 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,059 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]7736
2025-07-15T14:23:03,060 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,060 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:03,060 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:03,061 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,061 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,061 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,061 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,061 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,062 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:03,062 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:03,062 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:03,062 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:03,062 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 2 seconds.
2025-07-15T14:23:03,062 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 2 seconds.
2025-07-15T14:23:03,108 [ERROR] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:03,108 [ERROR] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:03,752 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=7948
2025-07-15T14:23:03,753 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:03,767 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,767 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]7948
2025-07-15T14:23:03,768 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:03,768 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,768 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,768 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:03,769 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,769 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,770 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,770 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,770 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:23:03,771 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:03,771 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:03,771 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:03,771 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:03,771 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 2 seconds.
2025-07-15T14:23:03,771 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 2 seconds.
2025-07-15T14:23:03,845 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=7968
2025-07-15T14:23:03,845 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:03,859 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,859 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]7968
2025-07-15T14:23:03,860 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,860 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,860 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:03,860 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:03,861 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:23:03,861 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,861 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,861 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,861 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,862 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:03,862 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:03,862 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:03,862 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:03,862 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 2 seconds.
2025-07-15T14:23:03,862 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 2 seconds.
2025-07-15T14:23:03,920 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=7986
2025-07-15T14:23:03,920 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:03,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]7986
2025-07-15T14:23:03,932 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,933 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:03,933 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:03,933 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,933 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,933 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,933 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:03,934 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:03,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-07-15T14:23:03,934 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2025-07-15T14:23:03,938 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=7932
2025-07-15T14:23:03,938 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:03,960 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,960 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]7932
2025-07-15T14:23:03,961 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,961 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,961 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:03,961 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:03,962 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,962 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,962 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,962 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,962 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:23:03,963 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:03,963 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:03,963 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:03,963 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:03,963 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 2 seconds.
2025-07-15T14:23:03,963 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 2 seconds.
2025-07-15T14:23:03,981 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:03,981 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:03,982 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:03,982 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:03,982 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=7995
2025-07-15T14:23:03,983 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:03,988 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=7959
2025-07-15T14:23:03,988 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]7995
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:03,997 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:03,998 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,998 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:03,998 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,998 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:03,999 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:03,999 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:03,999 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:03,999 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:03,999 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 2 seconds.
2025-07-15T14:23:03,999 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 2 seconds.
2025-07-15T14:23:04,002 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,003 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]7959
2025-07-15T14:23:04,003 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,003 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,003 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:04,003 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:04,004 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,004 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,004 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9025.
2025-07-15T14:23:04,004 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,004 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,005 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:04,005 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:04,005 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:04,005 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:04,005 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 2 seconds.
2025-07-15T14:23:04,005 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 2 seconds.
2025-07-15T14:23:04,041 [ERROR] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,041 [ERROR] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,100 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:04,100 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:04,100 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:04,100 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:04,124 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=8102
2025-07-15T14:23:04,124 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:04,137 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,138 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]8102
2025-07-15T14:23:04,138 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:04,138 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:04,138 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,138 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,139 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,139 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2025-07-15T14:23:04,139 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,139 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,139 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,140 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:04,140 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:04,140 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:04,140 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:04,140 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-07-15T14:23:04,140 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2025-07-15T14:23:04,181 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=8116
2025-07-15T14:23:04,182 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:04,196 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,196 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - [PID]8116
2025-07-15T14:23:04,197 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,197 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,197 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:04,197 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:04,198 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9046.
2025-07-15T14:23:04,198 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,198 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:04,198 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:04,199 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 2 seconds.
2025-07-15T14:23:04,199 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 2 seconds.
2025-07-15T14:23:04,220 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9016, pid=7981
2025-07-15T14:23:04,221 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:04,227 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=8128
2025-07-15T14:23:04,228 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - [PID]7981
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:04,235 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,236 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,236 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9016.
2025-07-15T14:23:04,236 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,236 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,236 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,237 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:04,237 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:04,237 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:04,237 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:04,237 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 2 seconds.
2025-07-15T14:23:04,237 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 2 seconds.
2025-07-15T14:23:04,237 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9027, pid=8122
2025-07-15T14:23:04,237 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:04,241 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9017, pid=7989
2025-07-15T14:23:04,241 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]8128
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,242 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:04,243 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2025-07-15T14:23:04,243 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,243 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,244 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,244 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,245 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:04,245 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:04,245 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:04,245 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:04,245 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 2 seconds.
2025-07-15T14:23:04,245 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 2 seconds.
2025-07-15T14:23:04,252 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,253 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - [PID]8122
2025-07-15T14:23:04,253 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,253 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,253 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:04,253 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:04,254 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,254 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,254 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,254 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,255 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:04,255 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:04,255 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:04,255 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:04,255 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 2 seconds.
2025-07-15T14:23:04,255 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 2 seconds.
2025-07-15T14:23:04,258 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,259 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - [PID]7989
2025-07-15T14:23:04,259 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,259 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:04,259 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:04,259 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,260 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9017.
2025-07-15T14:23:04,260 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,260 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,260 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,260 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,261 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:04,261 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:04,261 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:04,261 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:04,261 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 2 seconds.
2025-07-15T14:23:04,261 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 2 seconds.
2025-07-15T14:23:04,267 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9037, pid=7998
2025-07-15T14:23:04,267 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:04,277 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9024, pid=8132
2025-07-15T14:23:04,277 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:04,280 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9032, pid=8101
2025-07-15T14:23:04,280 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:04,286 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,287 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - [PID]7998
2025-07-15T14:23:04,287 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,287 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:04,287 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:04,288 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=8098
2025-07-15T14:23:04,288 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:04,289 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,289 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,289 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,289 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,290 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:04,290 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:04,290 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:04,290 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:04,290 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 2 seconds.
2025-07-15T14:23:04,290 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 2 seconds.
2025-07-15T14:23:04,290 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,291 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - [PID]8132
2025-07-15T14:23:04,291 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,291 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,291 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:04,291 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:04,292 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,292 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9024.
2025-07-15T14:23:04,292 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,292 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,292 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,293 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:04,293 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:04,293 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:04,293 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:04,293 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 2 seconds.
2025-07-15T14:23:04,293 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 2 seconds.
2025-07-15T14:23:04,296 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=8113
2025-07-15T14:23:04,296 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:04,296 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,297 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - [PID]8101
2025-07-15T14:23:04,297 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,297 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:04,297 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:04,298 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,298 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,298 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9032.
2025-07-15T14:23:04,298 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,298 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,298 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,299 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:04,299 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:04,299 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:04,299 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:04,299 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 2 seconds.
2025-07-15T14:23:04,299 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 2 seconds.
2025-07-15T14:23:04,305 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,305 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]8098
2025-07-15T14:23:04,305 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,305 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:04,305 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:04,306 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,306 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,306 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,306 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,306 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,307 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:04,307 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:04,307 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:04,307 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:04,307 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 2 seconds.
2025-07-15T14:23:04,307 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 2 seconds.
2025-07-15T14:23:04,312 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=8119
2025-07-15T14:23:04,312 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,313 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:04,313 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]8113
2025-07-15T14:23:04,313 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,313 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:04,313 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,313 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:04,314 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,314 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2025-07-15T14:23:04,314 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,314 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,314 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,315 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:04,315 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:04,315 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:04,315 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:04,315 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-07-15T14:23:04,315 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2025-07-15T14:23:04,325 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]8119
2025-07-15T14:23:04,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,326 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,326 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:04,326 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:04,327 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,327 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,327 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,327 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,329 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:04,329 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:04,329 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:04,329 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:04,329 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-07-15T14:23:04,329 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2025-07-15T14:23:04,333 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9022, pid=8140
2025-07-15T14:23:04,335 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:04,336 [ERROR] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,336 [ERROR] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,346 [ERROR] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,346 [ERROR] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,349 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9043, pid=7990
2025-07-15T14:23:04,349 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - [PID]8140
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,361 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:04,362 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,362 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - [PID]7990
2025-07-15T14:23:04,362 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,362 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,362 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:04,362 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,362 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,363 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,363 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9043.
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:04,363 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:04,363 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,363 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 2 seconds.
2025-07-15T14:23:04,363 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,363 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 2 seconds.
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:04,364 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:04,364 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 2 seconds.
2025-07-15T14:23:04,364 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 2 seconds.
2025-07-15T14:23:04,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=8095
2025-07-15T14:23:04,365 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:04,371 [ERROR] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,371 [ERROR] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,384 [ERROR] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,384 [ERROR] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,392 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,404 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9033, pid=8131
2025-07-15T14:23:04,404 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:04,406 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]8095
2025-07-15T14:23:04,406 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,406 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:04,406 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:04,407 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2025-07-15T14:23:04,407 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,407 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,407 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,407 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,408 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:04,408 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:04,408 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:04,408 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:04,408 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-07-15T14:23:04,408 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2025-07-15T14:23:04,409 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9042, pid=8110
2025-07-15T14:23:04,410 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:04,417 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,418 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - [PID]8131
2025-07-15T14:23:04,418 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,418 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,418 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:04,418 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:04,419 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,419 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,419 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,419 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,420 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:04,420 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:04,420 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:04,420 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:04,420 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 2 seconds.
2025-07-15T14:23:04,420 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 2 seconds.
2025-07-15T14:23:04,420 [ERROR] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,420 [ERROR] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,421 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9023, pid=8103
2025-07-15T14:23:04,422 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:04,423 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,423 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - [PID]8110
2025-07-15T14:23:04,424 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,424 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:04,424 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:04,424 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,424 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9042.
2025-07-15T14:23:04,424 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,424 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:04,425 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:04,426 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 2 seconds.
2025-07-15T14:23:04,426 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 2 seconds.
2025-07-15T14:23:04,435 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,438 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - [PID]8103
2025-07-15T14:23:04,438 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,438 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,438 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:04,438 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:04,439 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,439 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,439 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,439 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,440 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:04,440 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:04,440 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:04,440 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:04,440 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 2 seconds.
2025-07-15T14:23:04,440 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 2 seconds.
2025-07-15T14:23:04,456 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9018, pid=8137
2025-07-15T14:23:04,457 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:04,462 [ERROR] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,462 [ERROR] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,470 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,471 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - [PID]8137
2025-07-15T14:23:04,471 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,471 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:04,471 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,471 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:04,472 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,472 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,472 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,472 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,472 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:04,472 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:04,473 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:04,473 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:04,473 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 2 seconds.
2025-07-15T14:23:04,473 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 2 seconds.
2025-07-15T14:23:04,486 [ERROR] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,486 [ERROR] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,514 [ERROR] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,514 [ERROR] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,526 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:04,526 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:04,526 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:04,526 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:04,560 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9036, pid=8125
2025-07-15T14:23:04,560 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:04,571 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=8143
2025-07-15T14:23:04,571 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:04,574 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,575 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - [PID]8125
2025-07-15T14:23:04,575 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,575 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,575 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:04,575 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:04,576 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9036.
2025-07-15T14:23:04,576 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,576 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,576 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,576 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,577 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:04,577 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:04,577 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:04,577 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:04,577 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 2 seconds.
2025-07-15T14:23:04,577 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 2 seconds.
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]8143
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:04,586 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:04,588 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,588 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,588 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,588 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,589 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:04,589 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:04,589 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:04,589 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:04,589 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 2 seconds.
2025-07-15T14:23:04,589 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 2 seconds.
2025-07-15T14:23:04,638 [ERROR] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,638 [ERROR] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:04,729 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:04,729 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:04,729 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:04,729 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:04,738 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:04,738 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:04,738 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:04,738 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:04,772 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:04,772 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:04,772 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:04,772 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:04,785 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9040, pid=8146
2025-07-15T14:23:04,786 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - [PID]8146
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:04,797 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:04,798 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9040.
2025-07-15T14:23:04,798 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,798 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,799 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,799 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,800 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:04,800 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:04,801 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:04,801 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:04,801 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 2 seconds.
2025-07-15T14:23:04,801 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 2 seconds.
2025-07-15T14:23:04,814 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=8161
2025-07-15T14:23:04,814 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:04,815 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:04,815 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:04,815 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:04,815 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:04,815 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:04,815 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:04,815 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:04,815 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:04,828 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,828 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]8161
2025-07-15T14:23:04,828 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,828 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,829 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:04,829 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:04,830 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2025-07-15T14:23:04,831 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,831 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,833 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,833 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,834 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=8147
2025-07-15T14:23:04,834 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9044, pid=8155
2025-07-15T14:23:04,834 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:04,834 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:04,834 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:04,834 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:04,834 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:04,834 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 2 seconds.
2025-07-15T14:23:04,834 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 2 seconds.
2025-07-15T14:23:04,834 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:04,846 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,847 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]8147
2025-07-15T14:23:04,847 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,847 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,847 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:04,847 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:04,848 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,848 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2025-07-15T14:23:04,848 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,848 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,848 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,849 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,849 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - [PID]8155
2025-07-15T14:23:04,850 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,850 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:04,850 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:04,850 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,851 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,851 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,851 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9044.
2025-07-15T14:23:04,851 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,851 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,852 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:04,852 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:04,852 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:04,852 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:04,852 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2025-07-15T14:23:04,852 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2025-07-15T14:23:04,852 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:04,852 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:04,852 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:04,852 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:04,852 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 2 seconds.
2025-07-15T14:23:04,852 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 2 seconds.
2025-07-15T14:23:04,854 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:04,854 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:04,855 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:04,855 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:04,855 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=8176
2025-07-15T14:23:04,856 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:04,861 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9039, pid=8158
2025-07-15T14:23:04,862 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:04,870 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]8176
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:04,871 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,871 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2025-07-15T14:23:04,871 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:04,872 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:04,872 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-07-15T14:23:04,872 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - [PID]8158
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:04,876 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:04,877 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,877 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9039.
2025-07-15T14:23:04,877 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,877 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9021, pid=8164
2025-07-15T14:23:04,877 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:04,878 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,878 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,879 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:04,879 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:04,879 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:04,879 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:04,879 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 2 seconds.
2025-07-15T14:23:04,879 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 2 seconds.
2025-07-15T14:23:04,879 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=8182
2025-07-15T14:23:04,879 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:04,882 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=8313
2025-07-15T14:23:04,882 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9035, pid=8167
2025-07-15T14:23:04,882 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:04,882 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:04,882 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9020, pid=8152
2025-07-15T14:23:04,882 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:04,890 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9029, pid=8382
2025-07-15T14:23:04,890 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:04,890 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9030, pid=8173
2025-07-15T14:23:04,890 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:04,891 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,892 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - [PID]8164
2025-07-15T14:23:04,892 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,892 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,892 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:04,892 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:04,892 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9034, pid=8329
2025-07-15T14:23:04,892 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,892 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:04,893 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]8182
2025-07-15T14:23:04,893 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,893 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,893 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,893 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:04,893 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:04,893 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,893 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,893 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9021.
2025-07-15T14:23:04,893 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,895 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,895 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,895 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,893 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,895 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2025-07-15T14:23:04,893 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9028, pid=8279
2025-07-15T14:23:04,895 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:04,893 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,895 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]8313
2025-07-15T14:23:04,896 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:04,896 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:04,896 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,896 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:04,896 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:04,896 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:04,896 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:04,896 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,896 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2025-07-15T14:23:04,896 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,896 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2025-07-15T14:23:04,896 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:04,896 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:04,896 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:04,896 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:04,896 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 2 seconds.
2025-07-15T14:23:04,896 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 2 seconds.
2025-07-15T14:23:04,896 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,896 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,896 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,897 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2025-07-15T14:23:04,897 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - [PID]8167
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,897 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,897 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,897 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:04,897 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:04,898 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,897 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:04,898 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,900 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 2 seconds.
2025-07-15T14:23:04,900 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 2 seconds.
2025-07-15T14:23:04,898 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9035.
2025-07-15T14:23:04,898 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - [PID]8152
2025-07-15T14:23:04,900 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,900 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,900 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:04,900 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:04,900 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:04,900 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 2 seconds.
2025-07-15T14:23:04,900 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 2 seconds.
2025-07-15T14:23:04,902 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,902 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,902 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9020.
2025-07-15T14:23:04,902 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,902 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,902 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=8177
2025-07-15T14:23:04,902 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:04,903 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:04,903 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:04,903 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:04,903 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:04,903 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 2 seconds.
2025-07-15T14:23:04,903 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 2 seconds.
2025-07-15T14:23:04,903 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,903 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - [PID]8382
2025-07-15T14:23:04,904 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:04,904 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,904 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,904 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:04,904 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,904 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,905 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9029.
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:04,905 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:04,905 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 2 seconds.
2025-07-15T14:23:04,905 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,905 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 2 seconds.
2025-07-15T14:23:04,906 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - [PID]8173
2025-07-15T14:23:04,906 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,906 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:04,906 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:04,906 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,906 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,907 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - [PID]8329
2025-07-15T14:23:04,907 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,907 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:04,907 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:04,907 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,907 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9030.
2025-07-15T14:23:04,908 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,908 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9034.
2025-07-15T14:23:04,908 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,908 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,908 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:04,908 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:04,908 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 2 seconds.
2025-07-15T14:23:04,908 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 2 seconds.
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:04,909 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:04,909 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 2 seconds.
2025-07-15T14:23:04,909 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 2 seconds.
2025-07-15T14:23:04,909 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,909 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - [PID]8279
2025-07-15T14:23:04,910 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,910 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,910 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:04,910 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:04,910 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:04,910 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:04,910 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:04,910 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:04,910 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,910 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,911 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9028.
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:04,911 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:04,911 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 2 seconds.
2025-07-15T14:23:04,911 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 2 seconds.
2025-07-15T14:23:04,915 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]8177
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:04,916 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2025-07-15T14:23:04,916 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,916 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:04,917 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:04,917 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 2 seconds.
2025-07-15T14:23:04,917 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 2 seconds.
2025-07-15T14:23:04,965 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:04,965 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:04,965 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:04,965 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:04,992 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9045, pid=8170
2025-07-15T14:23:04,993 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:05,000 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9047, pid=8379
2025-07-15T14:23:05,001 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - [PID]8170
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:05,006 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:05,007 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,007 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9045.
2025-07-15T14:23:05,007 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,008 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,008 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,008 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:05,008 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:05,009 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:05,009 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:05,009 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 2 seconds.
2025-07-15T14:23:05,009 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 2 seconds.
2025-07-15T14:23:05,011 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:05,012 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - [PID]8379
2025-07-15T14:23:05,012 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:05,012 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:05,012 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:05,012 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:05,013 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9047.
2025-07-15T14:23:05,013 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,013 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,013 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,013 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,014 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:05,014 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:05,014 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:05,014 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:05,015 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 2 seconds.
2025-07-15T14:23:05,015 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 2 seconds.
2025-07-15T14:23:05,021 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:05,021 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:05,021 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:05,021 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:05,027 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9026, pid=8529
2025-07-15T14:23:05,027 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - [PID]8529
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:05,036 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:05,037 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9026.
2025-07-15T14:23:05,037 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,037 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:05,037 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,037 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:05,038 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:05,038 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:05,038 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:05,038 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:05,038 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 3 seconds.
2025-07-15T14:23:05,038 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 3 seconds.
2025-07-15T14:23:05,048 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:05,048 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:05,048 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:05,048 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:05,048 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:05,048 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:05,048 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:05,048 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:05,067 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:05,067 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:05,067 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:05,067 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:05,073 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:05,073 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:05,073 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:05,073 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:05,082 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:05,082 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:05,082 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:05,082 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:05,087 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:05,088 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:05,087 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:05,087 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:05,088 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:05,087 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:05,087 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:05,087 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:05,095 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:05,095 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:05,095 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:05,095 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:05,132 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:05,132 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:05,132 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:05,132 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:05,143 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:05,143 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:05,143 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:05,143 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:05,197 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:05,197 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:05,197 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:05,197 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:05,228 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:05,228 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:05,228 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:05,228 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:05,230 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:05,230 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:05,230 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:05,230 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:05,246 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:05,246 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:05,246 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:05,246 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:05,324 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:05,324 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:05,324 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:05,324 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:05,336 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:05,336 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:05,336 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:05,336 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:05,350 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:05,350 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:05,350 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:05,350 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:05,423 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:05,423 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:05,423 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:05,423 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:05,467 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:05,467 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:05,467 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:05,467 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:05,480 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:05,480 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:05,480 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:05,480 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:05,483 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:05,483 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:05,483 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:05,483 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:05,484 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:05,484 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:05,484 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:05,484 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:05,488 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:05,488 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:05,488 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:05,488 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:05,491 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:05,491 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:05,491 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:05,491 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:05,492 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:05,492 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:05,492 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:05,492 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:05,495 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:05,495 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:05,495 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:05,495 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:05,496 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:05,496 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:05,496 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:05,496 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:05,512 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:05,512 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:05,512 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:05,512 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:05,518 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:05,518 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:05,519 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:05,519 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:05,533 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:05,533 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:05,533 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:05,533 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:05,554 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:05,554 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:05,554 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:05,554 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:05,570 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:05,570 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:05,570 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:05,570 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:05,578 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:05,578 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:05,578 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:05,578 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:05,578 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:05,578 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:05,578 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:05,578 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:05,593 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:05,593 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:05,593 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:05,593 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:05,599 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:05,599 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:05,599 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:05,599 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:06,389 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=10569
2025-07-15T14:23:06,389 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:06,400 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:06,401 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]10569
2025-07-15T14:23:06,401 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:06,401 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:06,401 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:06,401 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:06,401 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:06,401 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:06,402 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9041.
2025-07-15T14:23:06,402 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:06,402 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:06,403 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:06,403 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:06,409 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:06,409 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:06,409 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 3 seconds.
2025-07-15T14:23:06,409 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 3 seconds.
2025-07-15T14:23:06,443 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=10572
2025-07-15T14:23:06,449 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:06,461 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:06,467 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]10572
2025-07-15T14:23:06,467 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:06,467 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:06,467 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:06,467 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:06,468 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:06,468 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:06,468 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9031.
2025-07-15T14:23:06,468 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:06,468 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:06,469 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:06,469 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:06,469 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:06,469 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:06,469 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 3 seconds.
2025-07-15T14:23:06,469 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 3 seconds.
2025-07-15T14:23:07,162 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:07,162 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:07,163 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:07,163 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:07,224 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:07,224 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:07,225 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:07,225 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:07,748 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=10707
2025-07-15T14:23:07,749 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:07,763 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:07,764 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]10707
2025-07-15T14:23:07,764 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:07,764 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:07,764 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:07,765 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:07,765 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:07,765 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:07,765 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:23:07,765 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:07,765 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:07,766 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:07,766 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:07,766 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:07,766 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:07,766 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 3 seconds.
2025-07-15T14:23:07,766 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 3 seconds.
2025-07-15T14:23:07,854 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=10710
2025-07-15T14:23:07,854 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:07,867 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:07,868 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]10710
2025-07-15T14:23:07,868 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:07,868 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:07,868 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:07,868 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:07,869 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:07,869 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:23:07,869 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:07,869 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:07,869 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:07,870 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:07,870 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:07,870 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:07,870 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:07,870 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 3 seconds.
2025-07-15T14:23:07,870 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 3 seconds.
2025-07-15T14:23:07,991 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=10713
2025-07-15T14:23:07,991 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:08,004 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,005 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]10713
2025-07-15T14:23:08,005 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:08,005 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,005 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:08,006 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,006 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:23:08,006 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,006 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,006 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,006 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,007 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:08,007 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:08,007 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:08,007 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:08,007 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-07-15T14:23:08,007 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2025-07-15T14:23:08,269 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=10722
2025-07-15T14:23:08,270 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:08,275 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,275 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]10722
2025-07-15T14:23:08,275 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,275 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:08,275 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:08,276 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,276 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,276 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,276 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,277 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:08,277 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:08,277 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:08,277 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:08,277 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 3 seconds.
2025-07-15T14:23:08,277 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 3 seconds.
2025-07-15T14:23:08,343 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=10719
2025-07-15T14:23:08,343 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:08,400 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,400 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]10719
2025-07-15T14:23:08,401 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:08,401 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,401 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,401 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:08,402 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,402 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,402 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,402 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9038.
2025-07-15T14:23:08,402 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,403 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:08,403 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:08,403 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:08,403 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:08,403 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 3 seconds.
2025-07-15T14:23:08,403 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 3 seconds.
2025-07-15T14:23:08,413 [ERROR] epollEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:08,413 [ERROR] epollEventLoopGroup-5-54 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:08,463 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=10716
2025-07-15T14:23:08,463 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:08,478 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,479 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]10716
2025-07-15T14:23:08,479 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,479 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:08,479 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:08,479 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,480 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,480 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,480 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:23:08,480 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,480 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,481 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:08,481 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:08,481 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:08,481 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:08,481 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 3 seconds.
2025-07-15T14:23:08,481 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 3 seconds.
2025-07-15T14:23:08,569 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9016, pid=10731
2025-07-15T14:23:08,569 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:08,583 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,583 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - [PID]10731
2025-07-15T14:23:08,583 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,583 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,584 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:08,584 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:08,584 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,584 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9016.
2025-07-15T14:23:08,584 [INFO ] epollEventLoopGroup-5-41 org.pytorch.serve.wlm.WorkerThread - 9016 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stderr
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:08,585 [WARN ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9016-model_1.0-stdout
2025-07-15T14:23:08,585 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 3 seconds.
2025-07-15T14:23:08,585 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9016 in 3 seconds.
2025-07-15T14:23:08,650 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9024, pid=10746
2025-07-15T14:23:08,650 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:08,665 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,666 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - [PID]10746
2025-07-15T14:23:08,666 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,666 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,667 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:08,667 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:08,668 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,668 [INFO ] epollEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9024 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,668 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,668 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,669 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:08,669 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stderr
2025-07-15T14:23:08,669 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:08,669 [WARN ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9024-model_1.0-stdout
2025-07-15T14:23:08,669 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 3 seconds.
2025-07-15T14:23:08,669 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9024 in 3 seconds.
2025-07-15T14:23:08,676 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:08,676 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:08,676 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:08,676 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:08,677 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=10725
2025-07-15T14:23:08,677 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=10728
2025-07-15T14:23:08,677 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:08,677 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]10725
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,689 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:08,690 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2025-07-15T14:23:08,690 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,690 [INFO ] epollEventLoopGroup-5-22 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,690 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,690 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,691 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:08,691 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stderr
2025-07-15T14:23:08,691 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:08,691 [WARN ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-model_1.0-stdout
2025-07-15T14:23:08,691 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-07-15T14:23:08,691 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2025-07-15T14:23:08,692 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,692 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - [PID]10728
2025-07-15T14:23:08,693 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,693 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:08,693 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:08,693 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,694 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,694 [INFO ] epollEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9046 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,694 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,694 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,695 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:08,695 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stderr
2025-07-15T14:23:08,695 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:08,695 [WARN ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9046-model_1.0-stdout
2025-07-15T14:23:08,695 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 3 seconds.
2025-07-15T14:23:08,695 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9046 in 3 seconds.
2025-07-15T14:23:08,718 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9027, pid=10737
2025-07-15T14:23:08,718 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:08,724 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=10755
2025-07-15T14:23:08,724 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:08,729 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,729 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - [PID]10737
2025-07-15T14:23:08,730 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,730 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:08,730 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:08,730 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,730 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,730 [INFO ] epollEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9027 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,731 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9027.
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stderr
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:08,731 [WARN ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9027-model_1.0-stdout
2025-07-15T14:23:08,731 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 3 seconds.
2025-07-15T14:23:08,731 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9027 in 3 seconds.
2025-07-15T14:23:08,731 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9017, pid=10740
2025-07-15T14:23:08,732 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:08,735 [ERROR] epollEventLoopGroup-5-60 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:08,735 [ERROR] epollEventLoopGroup-5-60 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:08,738 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,739 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]10755
2025-07-15T14:23:08,739 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,739 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,739 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:08,739 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:08,740 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2025-07-15T14:23:08,740 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,740 [INFO ] epollEventLoopGroup-5-32 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,740 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,740 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,741 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:08,741 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stderr
2025-07-15T14:23:08,741 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:08,741 [WARN ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-model_1.0-stdout
2025-07-15T14:23:08,741 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-07-15T14:23:08,741 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2025-07-15T14:23:08,746 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:08,746 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:08,746 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:08,746 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:08,746 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,747 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - [PID]10740
2025-07-15T14:23:08,747 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,747 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:08,747 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,747 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:08,748 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,748 [INFO ] epollEventLoopGroup-5-20 org.pytorch.serve.wlm.WorkerThread - 9017 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,748 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,748 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,748 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9017.
2025-07-15T14:23:08,749 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:08,749 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stderr
2025-07-15T14:23:08,749 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:08,749 [WARN ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9017-model_1.0-stdout
2025-07-15T14:23:08,749 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 3 seconds.
2025-07-15T14:23:08,749 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9017 in 3 seconds.
2025-07-15T14:23:08,782 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=10752
2025-07-15T14:23:08,782 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:08,797 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,797 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]10752
2025-07-15T14:23:08,798 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,798 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:08,798 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:08,798 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,798 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,798 [INFO ] epollEventLoopGroup-5-39 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,798 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stderr
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:08,799 [WARN ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9009-model_1.0-stdout
2025-07-15T14:23:08,800 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 3 seconds.
2025-07-15T14:23:08,800 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9009 in 3 seconds.
2025-07-15T14:23:08,805 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=10734
2025-07-15T14:23:08,805 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:08,820 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,820 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]10734
2025-07-15T14:23:08,820 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,821 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,821 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:08,821 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:08,821 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,821 [INFO ] epollEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,821 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2025-07-15T14:23:08,822 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,822 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,823 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:08,823 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stderr
2025-07-15T14:23:08,823 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:08,823 [WARN ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9014-model_1.0-stdout
2025-07-15T14:23:08,824 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 3 seconds.
2025-07-15T14:23:08,824 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9014 in 3 seconds.
2025-07-15T14:23:08,864 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9032, pid=10749
2025-07-15T14:23:08,864 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:08,877 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,878 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - [PID]10749
2025-07-15T14:23:08,878 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,878 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:08,878 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,878 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:08,879 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,879 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9032.
2025-07-15T14:23:08,879 [INFO ] epollEventLoopGroup-5-42 org.pytorch.serve.wlm.WorkerThread - 9032 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,879 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,879 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,880 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:08,880 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stderr
2025-07-15T14:23:08,880 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:08,880 [WARN ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9032-model_1.0-stdout
2025-07-15T14:23:08,880 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 3 seconds.
2025-07-15T14:23:08,880 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9032 in 3 seconds.
2025-07-15T14:23:08,893 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=10864
2025-07-15T14:23:08,894 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]10864
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,908 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:08,910 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,910 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,910 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2025-07-15T14:23:08,910 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,910 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,910 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9036, pid=10883
2025-07-15T14:23:08,911 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:08,911 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stderr
2025-07-15T14:23:08,911 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:08,911 [WARN ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-model_1.0-stdout
2025-07-15T14:23:08,911 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-07-15T14:23:08,911 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2025-07-15T14:23:08,911 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:08,925 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,925 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - [PID]10883
2025-07-15T14:23:08,925 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:08,925 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,925 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:08,926 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,926 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9036.
2025-07-15T14:23:08,926 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,926 [INFO ] epollEventLoopGroup-5-33 org.pytorch.serve.wlm.WorkerThread - 9036 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,927 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,927 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,928 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:08,928 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stderr
2025-07-15T14:23:08,928 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:08,928 [WARN ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9036-model_1.0-stdout
2025-07-15T14:23:08,928 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 3 seconds.
2025-07-15T14:23:08,928 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9036 in 3 seconds.
2025-07-15T14:23:08,938 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9023, pid=10871
2025-07-15T14:23:08,939 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:08,946 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:08,946 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:08,946 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:08,946 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:08,947 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9033, pid=10865
2025-07-15T14:23:08,947 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:08,953 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,954 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - [PID]10871
2025-07-15T14:23:08,954 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,954 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,954 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:08,954 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:08,955 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9023.
2025-07-15T14:23:08,955 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,955 [INFO ] epollEventLoopGroup-5-24 org.pytorch.serve.wlm.WorkerThread - 9023 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,955 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,955 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,956 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:08,956 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stderr
2025-07-15T14:23:08,956 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:08,956 [WARN ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9023-model_1.0-stdout
2025-07-15T14:23:08,956 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 3 seconds.
2025-07-15T14:23:08,956 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9023 in 3 seconds.
2025-07-15T14:23:08,961 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:08,962 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - [PID]10865
2025-07-15T14:23:08,962 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:08,962 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:08,962 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:08,963 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:08,963 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,963 [INFO ] epollEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9033 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:08,963 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,963 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:08,963 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9033.
2025-07-15T14:23:08,983 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:08,983 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stderr
2025-07-15T14:23:08,983 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:08,983 [WARN ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9033-model_1.0-stdout
2025-07-15T14:23:08,983 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 3 seconds.
2025-07-15T14:23:08,983 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9033 in 3 seconds.
2025-07-15T14:23:09,019 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9022, pid=10797
2025-07-15T14:23:09,020 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:09,029 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,030 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - [PID]10797
2025-07-15T14:23:09,030 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,030 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:09,030 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,030 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:09,031 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,031 [INFO ] epollEventLoopGroup-5-28 org.pytorch.serve.wlm.WorkerThread - 9022 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,031 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,031 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,031 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9022.
2025-07-15T14:23:09,032 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:09,032 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stderr
2025-07-15T14:23:09,032 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:09,032 [WARN ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9022-model_1.0-stdout
2025-07-15T14:23:09,032 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 3 seconds.
2025-07-15T14:23:09,032 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9022 in 3 seconds.
2025-07-15T14:23:09,043 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9037, pid=10743
2025-07-15T14:23:09,043 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:09,053 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=10758
2025-07-15T14:23:09,053 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - [PID]10743
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,056 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:09,058 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,058 [INFO ] epollEventLoopGroup-5-37 org.pytorch.serve.wlm.WorkerThread - 9037 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,058 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,058 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,066 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,067 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]10758
2025-07-15T14:23:09,067 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,067 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:09,067 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:09,068 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,068 [INFO ] epollEventLoopGroup-5-17 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,068 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,068 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,068 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,068 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2025-07-15T14:23:09,068 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:09,068 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stderr
2025-07-15T14:23:09,068 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:09,068 [WARN ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9037-model_1.0-stdout
2025-07-15T14:23:09,068 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 3 seconds.
2025-07-15T14:23:09,068 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9037 in 3 seconds.
2025-07-15T14:23:09,069 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:09,069 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stderr
2025-07-15T14:23:09,069 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:09,069 [WARN ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-model_1.0-stdout
2025-07-15T14:23:09,069 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-07-15T14:23:09,069 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2025-07-15T14:23:09,072 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9018, pid=10876
2025-07-15T14:23:09,072 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:09,072 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9042, pid=10867
2025-07-15T14:23:09,073 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:09,087 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,087 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - [PID]10867
2025-07-15T14:23:09,087 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,088 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,088 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:09,088 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:09,088 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,088 [INFO ] epollEventLoopGroup-5-19 org.pytorch.serve.wlm.WorkerThread - 9042 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,088 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9042.
2025-07-15T14:23:09,088 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,088 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,089 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:09,089 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stderr
2025-07-15T14:23:09,089 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:09,089 [WARN ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9042-model_1.0-stdout
2025-07-15T14:23:09,089 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 3 seconds.
2025-07-15T14:23:09,089 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9042 in 3 seconds.
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - [PID]10876
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:09,094 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:09,095 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9018.
2025-07-15T14:23:09,095 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,095 [INFO ] epollEventLoopGroup-5-35 org.pytorch.serve.wlm.WorkerThread - 9018 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,095 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,095 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,096 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:09,096 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stderr
2025-07-15T14:23:09,096 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:09,096 [WARN ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9018-model_1.0-stdout
2025-07-15T14:23:09,096 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 3 seconds.
2025-07-15T14:23:09,096 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9018 in 3 seconds.
2025-07-15T14:23:09,098 [ERROR] epollEventLoopGroup-5-72 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:09,098 [ERROR] epollEventLoopGroup-5-72 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:09,101 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9043, pid=10798
2025-07-15T14:23:09,101 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:09,111 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,111 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - [PID]10798
2025-07-15T14:23:09,111 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,111 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,112 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:09,112 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:09,112 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9043.
2025-07-15T14:23:09,112 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:09,112 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:09,112 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,112 [INFO ] W-9025-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stderr
2025-07-15T14:23:09,112 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9043 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,112 [INFO ] W-9025-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9025-model_1.0-stdout
2025-07-15T14:23:09,113 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,113 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,113 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:09,113 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stderr
2025-07-15T14:23:09,114 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:09,114 [WARN ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9043-model_1.0-stdout
2025-07-15T14:23:09,114 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 3 seconds.
2025-07-15T14:23:09,114 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9043 in 3 seconds.
2025-07-15T14:23:09,149 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:09,149 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:09,149 [INFO ] W-9019-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stdout
2025-07-15T14:23:09,149 [INFO ] W-9019-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9019-model_1.0-stderr
2025-07-15T14:23:09,168 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:09,168 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:09,168 [INFO ] W-9038-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stdout
2025-07-15T14:23:09,168 [INFO ] W-9038-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9038-model_1.0-stderr
2025-07-15T14:23:09,300 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:09,300 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:09,300 [INFO ] W-9016-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stdout
2025-07-15T14:23:09,300 [INFO ] W-9016-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9016-model_1.0-stderr
2025-07-15T14:23:09,357 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=11087
2025-07-15T14:23:09,357 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:09,369 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,369 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]11087
2025-07-15T14:23:09,370 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,370 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:09,370 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:09,370 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,370 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2025-07-15T14:23:09,370 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,370 [INFO ] epollEventLoopGroup-5-25 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stderr
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:09,371 [WARN ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-model_1.0-stdout
2025-07-15T14:23:09,371 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2025-07-15T14:23:09,371 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2025-07-15T14:23:09,423 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9020, pid=11111
2025-07-15T14:23:09,423 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:09,429 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:09,429 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:09,429 [INFO ] W-9027-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stdout
2025-07-15T14:23:09,429 [INFO ] W-9027-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9027-model_1.0-stderr
2025-07-15T14:23:09,437 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,438 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - [PID]11111
2025-07-15T14:23:09,438 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,438 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,438 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:09,438 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:09,439 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9020.
2025-07-15T14:23:09,439 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,439 [INFO ] epollEventLoopGroup-5-38 org.pytorch.serve.wlm.WorkerThread - 9020 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,439 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,439 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,440 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:09,440 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stderr
2025-07-15T14:23:09,440 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:09,440 [WARN ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9020-model_1.0-stdout
2025-07-15T14:23:09,440 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 3 seconds.
2025-07-15T14:23:09,440 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9020 in 3 seconds.
2025-07-15T14:23:09,443 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9021, pid=11100
2025-07-15T14:23:09,443 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:09,456 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,456 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - [PID]11100
2025-07-15T14:23:09,457 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,457 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:09,457 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:09,457 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,457 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,457 [INFO ] epollEventLoopGroup-5-27 org.pytorch.serve.wlm.WorkerThread - 9021 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,458 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9021.
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stderr
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:09,458 [WARN ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9021-model_1.0-stdout
2025-07-15T14:23:09,458 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 3 seconds.
2025-07-15T14:23:09,458 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9021 in 3 seconds.
2025-07-15T14:23:09,459 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9029, pid=11114
2025-07-15T14:23:09,460 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:09,465 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9028, pid=11123
2025-07-15T14:23:09,465 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:09,465 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:09,465 [INFO ] W-9046-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stderr
2025-07-15T14:23:09,465 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:09,465 [INFO ] W-9046-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9046-model_1.0-stdout
2025-07-15T14:23:09,465 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=10886
2025-07-15T14:23:09,466 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:09,472 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,473 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - [PID]11114
2025-07-15T14:23:09,473 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,473 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,473 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:09,473 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:09,474 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,474 [INFO ] epollEventLoopGroup-5-40 org.pytorch.serve.wlm.WorkerThread - 9029 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,474 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9029.
2025-07-15T14:23:09,474 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,474 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,475 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:09,475 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stderr
2025-07-15T14:23:09,476 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:09,475 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,476 [WARN ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9029-model_1.0-stdout
2025-07-15T14:23:09,476 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 3 seconds.
2025-07-15T14:23:09,476 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9029 in 3 seconds.
2025-07-15T14:23:09,476 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]10886
2025-07-15T14:23:09,476 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:09,476 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,476 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,476 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,476 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:09,476 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - [PID]11123
2025-07-15T14:23:09,477 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,477 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:09,477 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:09,477 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,477 [INFO ] epollEventLoopGroup-5-30 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,477 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,477 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2025-07-15T14:23:09,477 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,477 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,477 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,477 [INFO ] epollEventLoopGroup-5-23 org.pytorch.serve.wlm.WorkerThread - 9028 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,478 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9028.
2025-07-15T14:23:09,478 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,478 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,478 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:09,478 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stderr
2025-07-15T14:23:09,478 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:09,478 [WARN ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9015-model_1.0-stdout
2025-07-15T14:23:09,478 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 3 seconds.
2025-07-15T14:23:09,478 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9015 in 3 seconds.
2025-07-15T14:23:09,479 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:09,479 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stderr
2025-07-15T14:23:09,479 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:09,479 [WARN ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9028-model_1.0-stdout
2025-07-15T14:23:09,479 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 3 seconds.
2025-07-15T14:23:09,479 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9028 in 3 seconds.
2025-07-15T14:23:09,480 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=11093
2025-07-15T14:23:09,481 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:09,483 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9030, pid=11118
2025-07-15T14:23:09,483 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:09,486 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:09,486 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:09,486 [INFO ] W-9017-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stdout
2025-07-15T14:23:09,486 [INFO ] W-9017-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9017-model_1.0-stderr
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]11093
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:09,490 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:09,491 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,491 [INFO ] epollEventLoopGroup-5-18 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,491 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,491 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,491 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2025-07-15T14:23:09,492 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:09,492 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stderr
2025-07-15T14:23:09,492 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:09,492 [WARN ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-model_1.0-stdout
2025-07-15T14:23:09,492 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-07-15T14:23:09,492 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2025-07-15T14:23:09,497 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,497 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - [PID]11118
2025-07-15T14:23:09,497 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,498 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,498 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:09,498 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:09,498 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,498 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9030.
2025-07-15T14:23:09,498 [INFO ] epollEventLoopGroup-5-29 org.pytorch.serve.wlm.WorkerThread - 9030 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,498 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,498 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,499 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:09,499 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stderr
2025-07-15T14:23:09,499 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:09,499 [WARN ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9030-model_1.0-stdout
2025-07-15T14:23:09,499 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 3 seconds.
2025-07-15T14:23:09,499 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9030 in 3 seconds.
2025-07-15T14:23:09,513 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9034, pid=11117
2025-07-15T14:23:09,513 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:09,514 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:09,514 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:09,514 [INFO ] W-9004-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stdout
2025-07-15T14:23:09,514 [INFO ] W-9004-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-model_1.0-stderr
2025-07-15T14:23:09,517 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:09,517 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:09,517 [INFO ] W-9005-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stderr
2025-07-15T14:23:09,517 [INFO ] W-9005-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-model_1.0-stdout
2025-07-15T14:23:09,520 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:09,520 [INFO ] W-9024-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stdout
2025-07-15T14:23:09,520 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:09,520 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:09,520 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:09,520 [INFO ] W-9024-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9024-model_1.0-stderr
2025-07-15T14:23:09,520 [INFO ] W-9009-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stderr
2025-07-15T14:23:09,520 [INFO ] W-9009-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-model_1.0-stdout
2025-07-15T14:23:09,527 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,527 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - [PID]11117
2025-07-15T14:23:09,528 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,528 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,528 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:09,528 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:09,528 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,528 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9034.
2025-07-15T14:23:09,528 [INFO ] epollEventLoopGroup-5-34 org.pytorch.serve.wlm.WorkerThread - 9034 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stderr
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:09,529 [WARN ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9034-model_1.0-stdout
2025-07-15T14:23:09,529 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 3 seconds.
2025-07-15T14:23:09,529 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9034 in 3 seconds.
2025-07-15T14:23:09,542 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9039, pid=11096
2025-07-15T14:23:09,542 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:09,548 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9047, pid=11177
2025-07-15T14:23:09,549 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:09,550 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,551 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - [PID]11096
2025-07-15T14:23:09,551 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,551 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,551 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:09,551 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:09,551 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,551 [INFO ] epollEventLoopGroup-5-47 org.pytorch.serve.wlm.WorkerThread - 9039 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,552 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9039.
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stderr
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:09,552 [WARN ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9039-model_1.0-stdout
2025-07-15T14:23:09,552 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 3 seconds.
2025-07-15T14:23:09,552 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9039 in 3 seconds.
2025-07-15T14:23:09,560 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=11099
2025-07-15T14:23:09,560 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:09,560 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=11126
2025-07-15T14:23:09,561 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:09,561 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9040, pid=11081
2025-07-15T14:23:09,561 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,561 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:09,561 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - [PID]11177
2025-07-15T14:23:09,561 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,561 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,566 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9045, pid=11176
2025-07-15T14:23:09,567 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:09,567 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:09,567 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:09,567 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,567 [INFO ] epollEventLoopGroup-5-21 org.pytorch.serve.wlm.WorkerThread - 9047 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,567 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,567 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,567 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9047.
2025-07-15T14:23:09,568 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:09,568 [INFO ] W-9014-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stdout
2025-07-15T14:23:09,568 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:09,568 [INFO ] W-9014-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-model_1.0-stderr
2025-07-15T14:23:09,568 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:09,568 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stderr
2025-07-15T14:23:09,568 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:09,568 [WARN ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9047-model_1.0-stdout
2025-07-15T14:23:09,568 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 3 seconds.
2025-07-15T14:23:09,568 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9047 in 3 seconds.
2025-07-15T14:23:09,569 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:09,569 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:09,569 [INFO ] W-9001-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stdout
2025-07-15T14:23:09,569 [INFO ] W-9001-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-model_1.0-stderr
2025-07-15T14:23:09,570 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9035, pid=11106
2025-07-15T14:23:09,570 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:09,575 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,575 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - [PID]11081
2025-07-15T14:23:09,575 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,575 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,576 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:09,576 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:09,576 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9040.
2025-07-15T14:23:09,576 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,576 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,576 [INFO ] epollEventLoopGroup-5-45 org.pytorch.serve.wlm.WorkerThread - 9040 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,577 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,577 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,577 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]11099
2025-07-15T14:23:09,577 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,577 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,577 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:09,577 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:09,578 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:09,577 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=11084
2025-07-15T14:23:09,578 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stderr
2025-07-15T14:23:09,578 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:09,578 [WARN ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9040-model_1.0-stdout
2025-07-15T14:23:09,578 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:09,578 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,578 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2025-07-15T14:23:09,578 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 3 seconds.
2025-07-15T14:23:09,578 [INFO ] epollEventLoopGroup-5-31 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,578 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9040 in 3 seconds.
2025-07-15T14:23:09,578 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,578 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,579 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:09,579 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stderr
2025-07-15T14:23:09,579 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:09,579 [WARN ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-model_1.0-stdout
2025-07-15T14:23:09,579 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2025-07-15T14:23:09,579 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2025-07-15T14:23:09,580 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,580 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - [PID]11176
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]11126
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,581 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,582 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,581 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2025-07-15T14:23:09,582 [INFO ] epollEventLoopGroup-5-26 org.pytorch.serve.wlm.WorkerThread - 9045 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,581 [INFO ] epollEventLoopGroup-5-46 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,581 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9045.
2025-07-15T14:23:09,582 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,582 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,582 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,582 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,582 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,582 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:09,583 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:09,582 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stderr
2025-07-15T14:23:09,583 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:09,583 [WARN ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9045-model_1.0-stdout
2025-07-15T14:23:09,582 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - [PID]11106
2025-07-15T14:23:09,583 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 3 seconds.
2025-07-15T14:23:09,583 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stderr
2025-07-15T14:23:09,583 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:09,583 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9045 in 3 seconds.
2025-07-15T14:23:09,583 [WARN ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9011-model_1.0-stdout
2025-07-15T14:23:09,583 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 3 seconds.
2025-07-15T14:23:09,583 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,583 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9011 in 3 seconds.
2025-07-15T14:23:09,583 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:09,583 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:09,583 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,584 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,584 [INFO ] epollEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9035 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,584 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9035.
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stderr
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:09,584 [WARN ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9035-model_1.0-stdout
2025-07-15T14:23:09,585 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 3 seconds.
2025-07-15T14:23:09,585 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9035 in 3 seconds.
2025-07-15T14:23:09,596 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,597 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]11084
2025-07-15T14:23:09,597 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,597 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:09,597 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:09,608 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,608 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,608 [INFO ] epollEventLoopGroup-5-48 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,608 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stderr
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:09,609 [WARN ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9008-model_1.0-stdout
2025-07-15T14:23:09,610 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 3 seconds.
2025-07-15T14:23:09,610 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9008 in 3 seconds.
2025-07-15T14:23:09,624 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=11105
2025-07-15T14:23:09,626 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:09,629 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:09,629 [INFO ] W-9032-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stderr
2025-07-15T14:23:09,629 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:09,629 [INFO ] W-9032-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9032-model_1.0-stdout
2025-07-15T14:23:09,635 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9044, pid=11088
2025-07-15T14:23:09,635 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]11105
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,637 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:09,638 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,638 [INFO ] epollEventLoopGroup-5-44 org.pytorch.serve.wlm.WorkerThread - 9012 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,638 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stderr
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:09,638 [WARN ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9012-model_1.0-stdout
2025-07-15T14:23:09,638 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 3 seconds.
2025-07-15T14:23:09,638 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9012 in 3 seconds.
2025-07-15T14:23:09,639 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:09,639 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:09,639 [INFO ] W-9023-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stderr
2025-07-15T14:23:09,639 [INFO ] W-9023-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9023-model_1.0-stdout
2025-07-15T14:23:09,641 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:09,641 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:09,641 [INFO ] W-9036-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stdout
2025-07-15T14:23:09,641 [INFO ] W-9036-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9036-model_1.0-stderr
2025-07-15T14:23:09,648 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:09,648 [INFO ] W-9033-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stdout
2025-07-15T14:23:09,648 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:09,648 [INFO ] W-9033-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9033-model_1.0-stderr
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - [PID]11088
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:09,650 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:09,651 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,651 [INFO ] epollEventLoopGroup-5-36 org.pytorch.serve.wlm.WorkerThread - 9044 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:09,651 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9044.
2025-07-15T14:23:09,651 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,651 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:09,652 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:09,652 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stderr
2025-07-15T14:23:09,652 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:09,652 [WARN ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9044-model_1.0-stdout
2025-07-15T14:23:09,652 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 3 seconds.
2025-07-15T14:23:09,652 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9044 in 3 seconds.
2025-07-15T14:23:09,706 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:09,706 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:09,706 [INFO ] W-9037-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stdout
2025-07-15T14:23:09,706 [INFO ] W-9037-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9037-model_1.0-stderr
2025-07-15T14:23:09,753 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:09,753 [INFO ] W-9022-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stdout
2025-07-15T14:23:09,753 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:09,753 [INFO ] W-9022-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9022-model_1.0-stderr
2025-07-15T14:23:09,818 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:09,818 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:09,818 [INFO ] W-9043-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stdout
2025-07-15T14:23:09,818 [INFO ] W-9043-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9043-model_1.0-stderr
2025-07-15T14:23:09,847 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:09,847 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:09,847 [INFO ] W-9003-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stdout
2025-07-15T14:23:09,847 [INFO ] W-9003-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-model_1.0-stderr
2025-07-15T14:23:09,877 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:09,877 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:09,877 [INFO ] W-9042-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stdout
2025-07-15T14:23:09,877 [INFO ] W-9042-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9042-model_1.0-stderr
2025-07-15T14:23:09,885 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:09,885 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:09,885 [INFO ] W-9018-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stdout
2025-07-15T14:23:09,885 [INFO ] W-9018-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9018-model_1.0-stderr
2025-07-15T14:23:09,994 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:09,994 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:09,994 [INFO ] W-9006-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stdout
2025-07-15T14:23:09,994 [INFO ] W-9006-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-model_1.0-stderr
2025-07-15T14:23:10,041 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:10,041 [INFO ] W-9020-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stdout
2025-07-15T14:23:10,041 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:10,041 [INFO ] W-9020-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9020-model_1.0-stderr
2025-07-15T14:23:10,051 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:10,051 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:10,051 [INFO ] W-9002-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stdout
2025-07-15T14:23:10,051 [INFO ] W-9002-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-model_1.0-stderr
2025-07-15T14:23:10,059 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:10,058 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:10,059 [INFO ] W-9028-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stdout
2025-07-15T14:23:10,058 [INFO ] W-9028-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9028-model_1.0-stderr
2025-07-15T14:23:10,063 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:10,063 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:10,063 [INFO ] W-9029-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stderr
2025-07-15T14:23:10,063 [INFO ] W-9029-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9029-model_1.0-stdout
2025-07-15T14:23:10,066 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:10,066 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:10,066 [INFO ] W-9030-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stdout
2025-07-15T14:23:10,066 [INFO ] W-9030-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9030-model_1.0-stderr
2025-07-15T14:23:10,073 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:10,073 [INFO ] W-9021-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stdout
2025-07-15T14:23:10,073 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:10,073 [INFO ] W-9021-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9021-model_1.0-stderr
2025-07-15T14:23:10,092 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:10,092 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:10,092 [INFO ] W-9008-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stdout
2025-07-15T14:23:10,092 [INFO ] W-9008-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-model_1.0-stderr
2025-07-15T14:23:10,095 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:10,095 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:10,095 [INFO ] W-9015-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stderr
2025-07-15T14:23:10,095 [INFO ] W-9015-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-model_1.0-stdout
2025-07-15T14:23:10,103 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:10,103 [INFO ] W-9034-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stdout
2025-07-15T14:23:10,103 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:10,103 [INFO ] W-9034-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9034-model_1.0-stderr
2025-07-15T14:23:10,115 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:10,115 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:10,115 [INFO ] W-9011-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stdout
2025-07-15T14:23:10,115 [INFO ] W-9011-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-model_1.0-stderr
2025-07-15T14:23:10,127 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:10,127 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:10,127 [INFO ] W-9040-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stdout
2025-07-15T14:23:10,127 [INFO ] W-9040-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9040-model_1.0-stderr
2025-07-15T14:23:10,139 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:10,139 [INFO ] W-9045-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stdout
2025-07-15T14:23:10,139 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:10,139 [INFO ] W-9045-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9045-model_1.0-stderr
2025-07-15T14:23:10,140 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:10,140 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:10,140 [INFO ] W-9039-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stdout
2025-07-15T14:23:10,140 [INFO ] W-9039-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9039-model_1.0-stderr
2025-07-15T14:23:10,148 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:10,148 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:10,148 [INFO ] W-9047-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stderr
2025-07-15T14:23:10,148 [INFO ] W-9047-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9047-model_1.0-stdout
2025-07-15T14:23:10,166 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:10,166 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:10,166 [INFO ] W-9035-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stdout
2025-07-15T14:23:10,166 [INFO ] W-9035-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9035-model_1.0-stderr
2025-07-15T14:23:10,173 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:10,173 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:10,173 [INFO ] W-9007-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stderr
2025-07-15T14:23:10,173 [INFO ] W-9007-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-model_1.0-stdout
2025-07-15T14:23:10,248 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9026, pid=12086
2025-07-15T14:23:10,248 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:10,261 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:10,261 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - [PID]12086
2025-07-15T14:23:10,261 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:10,262 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:10,262 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:10,262 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,262 [INFO ] epollEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9026 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stderr
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:10,263 [WARN ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9026-model_1.0-stdout
2025-07-15T14:23:10,263 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 5 seconds.
2025-07-15T14:23:10,263 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9026 in 5 seconds.
2025-07-15T14:23:10,267 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:10,267 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:10,267 [INFO ] W-9044-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stdout
2025-07-15T14:23:10,267 [INFO ] W-9044-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9044-model_1.0-stderr
2025-07-15T14:23:10,279 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:10,279 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:10,279 [INFO ] W-9012-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stdout
2025-07-15T14:23:10,279 [INFO ] W-9012-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9012-model_1.0-stderr
2025-07-15T14:23:10,302 [ERROR] epollEventLoopGroup-5-96 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:10,302 [ERROR] epollEventLoopGroup-5-96 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2025-07-15T14:23:10,737 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:10,737 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:10,737 [INFO ] W-9026-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stderr
2025-07-15T14:23:10,737 [INFO ] W-9026-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9026-model_1.0-stdout
2025-07-15T14:23:10,882 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=13170
2025-07-15T14:23:10,883 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]13170
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:10,891 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:10,892 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9031.
2025-07-15T14:23:10,892 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,892 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9031 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,892 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,892 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,893 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:10,893 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stderr
2025-07-15T14:23:10,893 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:10,893 [WARN ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9031-model_1.0-stdout
2025-07-15T14:23:10,893 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 5 seconds.
2025-07-15T14:23:10,893 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9031 in 5 seconds.
2025-07-15T14:23:10,922 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=13148
2025-07-15T14:23:10,922 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:10,930 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]13148
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:10,931 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,931 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9041 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:10,931 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,931 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9041.
2025-07-15T14:23:10,931 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:10,932 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:10,932 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stderr
2025-07-15T14:23:10,932 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:10,932 [WARN ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9041-model_1.0-stdout
2025-07-15T14:23:10,932 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 5 seconds.
2025-07-15T14:23:10,932 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9041 in 5 seconds.
2025-07-15T14:23:11,361 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:11,361 [INFO ] W-9031-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stdout
2025-07-15T14:23:11,361 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:11,361 [INFO ] W-9031-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9031-model_1.0-stderr
2025-07-15T14:23:11,403 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:11,403 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:11,403 [INFO ] W-9041-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stdout
2025-07-15T14:23:11,403 [INFO ] W-9041-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9041-model_1.0-stderr
2025-07-15T14:23:12,160 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=13349
2025-07-15T14:23:12,160 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:12,173 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:12,173 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]13349
2025-07-15T14:23:12,174 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:12,173 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:12,174 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:12,174 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:12,174 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,174 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:23:12,174 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9013 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,175 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,175 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,176 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:12,176 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stderr
2025-07-15T14:23:12,176 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:12,176 [WARN ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9013-model_1.0-stdout
2025-07-15T14:23:12,176 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 5 seconds.
2025-07-15T14:23:12,176 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9013 in 5 seconds.
2025-07-15T14:23:12,273 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=13352
2025-07-15T14:23:12,273 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:12,286 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:12,287 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]13352
2025-07-15T14:23:12,287 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:12,287 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:12,287 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:12,287 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:12,287 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,287 [INFO ] epollEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,288 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stderr
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:12,288 [WARN ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9010-model_1.0-stdout
2025-07-15T14:23:12,288 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 5 seconds.
2025-07-15T14:23:12,288 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9010 in 5 seconds.
2025-07-15T14:23:12,617 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=13361
2025-07-15T14:23:12,617 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:12,631 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:12,632 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]13361
2025-07-15T14:23:12,632 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:12,632 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:12,632 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:12,632 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:12,633 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,633 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:12,633 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:23:12,633 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,633 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:12,634 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:12,634 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stderr
2025-07-15T14:23:12,634 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:12,634 [WARN ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-model_1.0-stdout
2025-07-15T14:23:12,634 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-07-15T14:23:12,634 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2025-07-15T14:23:12,887 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:12,887 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:12,887 [INFO ] W-9013-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stdout
2025-07-15T14:23:12,887 [INFO ] W-9013-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9013-model_1.0-stderr
2025-07-15T14:23:13,132 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:13,132 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:13,132 [INFO ] W-9010-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stdout
2025-07-15T14:23:13,132 [INFO ] W-9010-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-model_1.0-stderr
2025-07-15T14:23:13,400 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=13368
2025-07-15T14:23:13,400 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]13368
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:13,414 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:13,415 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,415 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9025.
2025-07-15T14:23:13,415 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9025 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,415 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,415 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,416 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:13,416 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stderr
2025-07-15T14:23:13,416 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:13,416 [WARN ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9025-model_1.0-stdout
2025-07-15T14:23:13,416 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 5 seconds.
2025-07-15T14:23:13,416 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9025 in 5 seconds.
2025-07-15T14:23:13,429 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=13418
2025-07-15T14:23:13,429 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:13,438 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]13418
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:13,439 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,439 [INFO ] epollEventLoopGroup-5-43 org.pytorch.serve.wlm.WorkerThread - 9038 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,439 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9038.
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stderr
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:13,440 [WARN ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9038-model_1.0-stdout
2025-07-15T14:23:13,441 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 5 seconds.
2025-07-15T14:23:13,441 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9038 in 5 seconds.
2025-07-15T14:23:13,517 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:13,517 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:13,517 [INFO ] W-9000-model_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stdout
2025-07-15T14:23:13,517 [INFO ] W-9000-model_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-model_1.0-stderr
2025-07-15T14:23:13,575 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=13468
2025-07-15T14:23:13,576 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:13,584 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:13,584 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]13468
2025-07-15T14:23:13,585 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:13,585 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:13,585 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:13,585 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:13,585 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:23:13,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9019 Worker disconnected. WORKER_STARTED
2025-07-15T14:23:13,585 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,585 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2025-07-15T14:23:13,586 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:13,586 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stderr
2025-07-15T14:23:13,586 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:13,586 [WARN ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9019-model_1.0-stdout
2025-07-15T14:23:13,586 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 5 seconds.
2025-07-15T14:23:13,586 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9019 in 5 seconds.
2025-07-15T14:23:13,724 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=13525
2025-07-15T14:23:13,725 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:21,197 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-07-15T14:23:21,197 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-07-15T14:23:21,250 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-07-15T14:23:21,250 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
2025-07-15T14:23:21,384 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.0
TS Home: /opt/conda/lib/python3.10/site-packages
Current directory: /opt/ml/code
Temp directory: /home/model-server/tmp
Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 48
Max heap size: 30688 M
Python executable: /opt/conda/bin/python3.10
Config file: /etc/sagemaker-ts.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8080
Metrics address: http://127.0.0.1:8082
Model Store: /opt/ml/code/.sagemaker/ts/models
Initial Models: model=/opt/ml/model
Log dir: /opt/ml/code/logs
Metrics dir: /opt/ml/code/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 48
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: true
Workflow Store: /opt/ml/code/.sagemaker/ts/models
Model config: N/A
2025-07-15T14:23:21,384 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.0
TS Home: /opt/conda/lib/python3.10/site-packages
Current directory: /opt/ml/code
Temp directory: /home/model-server/tmp
Metrics config path: /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 48
Max heap size: 30688 M
Python executable: /opt/conda/bin/python3.10
Config file: /etc/sagemaker-ts.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8080
Metrics address: http://127.0.0.1:8082
Model Store: /opt/ml/code/.sagemaker/ts/models
Initial Models: model=/opt/ml/model
Log dir: /opt/ml/code/logs
Metrics dir: /opt/ml/code/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 48
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: log
Disable system metrics: true
Workflow Store: /opt/ml/code/.sagemaker/ts/models
Model config: N/A
2025-07-15T14:23:21,390 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-07-15T14:23:21,390 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-07-15T14:23:21,406 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model
2025-07-15T14:23:21,406 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: /opt/ml/model
2025-07-15T14:23:21,408 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:23:21,408 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive version is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:23:21,409 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:23:21,409 [WARN ] main org.pytorch.serve.archive.model.ModelArchive - Model archive createdOn is not defined. Please upgrade to torch-model-archiver 0.2.0 or higher
2025-07-15T14:23:21,411 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.
2025-07-15T14:23:21,411 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.
2025-07-15T14:23:21,497 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-07-15T14:23:21,497 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2025-07-15T14:23:21,671 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-07-15T14:23:21,671 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-07-15T14:23:21,672 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-07-15T14:23:21,672 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2025-07-15T14:23:21,738 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-07-15T14:23:21,738 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2025-07-15T14:23:23,666 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9025, pid=223
2025-07-15T14:23:23,668 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:23,680 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,681 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - [PID]223
2025-07-15T14:23:23,682 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,683 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,688 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:23,688 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9025
2025-07-15T14:23:23,700 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9025.
2025-07-15T14:23:23,704 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403704
2025-07-15T14:23:23,704 [INFO ] W-9025-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403704
2025-07-15T14:23:23,741 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9030, pid=226
2025-07-15T14:23:23,743 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:23,744 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,744 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - [PID]226
2025-07-15T14:23:23,745 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,745 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,745 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:23,745 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9030
2025-07-15T14:23:23,748 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9030.
2025-07-15T14:23:23,751 [INFO ] W-9025-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,762 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403762
2025-07-15T14:23:23,762 [INFO ] W-9030-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403762
2025-07-15T14:23:23,762 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9045, pid=369
2025-07-15T14:23:23,762 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9017, pid=170
2025-07-15T14:23:23,763 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:23,764 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:23,777 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,778 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,778 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - [PID]170
2025-07-15T14:23:23,779 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,779 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - [PID]369
2025-07-15T14:23:23,779 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:23,780 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,779 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9017
2025-07-15T14:23:23,781 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:23,780 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,781 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,781 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9045
2025-07-15T14:23:23,783 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9011, pid=161
2025-07-15T14:23:23,784 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:23,793 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9045.
2025-07-15T14:23:23,794 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403794
2025-07-15T14:23:23,793 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9017.
2025-07-15T14:23:23,794 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403793
2025-07-15T14:23:23,794 [INFO ] W-9017-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403794
2025-07-15T14:23:23,794 [INFO ] W-9045-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403793
2025-07-15T14:23:23,797 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,797 [INFO ] W-9030-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,798 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - [PID]161
2025-07-15T14:23:23,799 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,799 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,799 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:23,799 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9011
2025-07-15T14:23:23,804 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403804
2025-07-15T14:23:23,804 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9011.
2025-07-15T14:23:23,804 [INFO ] W-9011-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403804
2025-07-15T14:23:23,805 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9016, pid=168
2025-07-15T14:23:23,806 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:23,811 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9036, pid=342
2025-07-15T14:23:23,812 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:23,820 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,830 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9014, pid=167
2025-07-15T14:23:23,824 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,831 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:23,831 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - [PID]342
2025-07-15T14:23:23,831 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,830 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9043, pid=355
2025-07-15T14:23:23,832 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:23,831 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9005, pid=145
2025-07-15T14:23:23,832 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9036
2025-07-15T14:23:23,834 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:23,832 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,830 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9021, pid=178
2025-07-15T14:23:23,830 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9034, pid=338
2025-07-15T14:23:23,830 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9037, pid=345
2025-07-15T14:23:23,835 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:23,835 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:23,835 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:23,835 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:23,835 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,830 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9028, pid=228
2025-07-15T14:23:23,836 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - [PID]355
2025-07-15T14:23:23,836 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,836 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:23,836 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:23,836 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,836 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9043
2025-07-15T14:23:23,837 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,837 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - [PID]228
2025-07-15T14:23:23,838 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,838 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:23,838 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,838 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9028
2025-07-15T14:23:23,839 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,840 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - [PID]178
2025-07-15T14:23:23,830 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9015, pid=165
2025-07-15T14:23:23,840 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:23,840 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:23,831 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9033, pid=235
2025-07-15T14:23:23,840 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9010, pid=158
2025-07-15T14:23:23,840 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,830 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9027, pid=220
2025-07-15T14:23:23,831 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - [PID]168
2025-07-15T14:23:23,841 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,841 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,841 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,841 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:23,842 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,841 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9016
2025-07-15T14:23:23,842 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,842 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:23,842 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - [PID]167
2025-07-15T14:23:23,842 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,842 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:23,842 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,842 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:23,843 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:23,836 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,843 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9014
2025-07-15T14:23:23,843 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - [PID]338
2025-07-15T14:23:23,844 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,844 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,844 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:23,844 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,844 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9034
2025-07-15T14:23:23,844 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,842 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - [PID]220
2025-07-15T14:23:23,844 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,840 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9021
2025-07-15T14:23:23,844 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - [PID]145
2025-07-15T14:23:23,844 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9046, pid=374
2025-07-15T14:23:23,845 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - [PID]165
2025-07-15T14:23:23,845 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:23,845 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:23,845 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,845 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9027
2025-07-15T14:23:23,845 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:23,845 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,845 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:23,846 [INFO ] W-9045-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,845 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9005
2025-07-15T14:23:23,845 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,845 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9015
2025-07-15T14:23:23,846 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,847 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,847 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9018, pid=172
2025-07-15T14:23:23,848 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - [PID]235
2025-07-15T14:23:23,848 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:23,848 [INFO ] W-9017-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,848 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9033
2025-07-15T14:23:23,848 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:23,848 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,849 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,849 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9036.
2025-07-15T14:23:23,850 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403850
2025-07-15T14:23:23,850 [INFO ] W-9036-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403850
2025-07-15T14:23:23,850 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,850 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - [PID]345
2025-07-15T14:23:23,850 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,851 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,851 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:23,851 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9037
2025-07-15T14:23:23,853 [INFO ] W-9011-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,854 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,854 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,854 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - [PID]158
2025-07-15T14:23:23,855 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,855 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:23,861 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,855 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9010
2025-07-15T14:23:23,862 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,862 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9019, pid=173
2025-07-15T14:23:23,863 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - [PID]172
2025-07-15T14:23:23,863 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:23,863 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,863 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9043.
2025-07-15T14:23:23,863 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,863 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9007, pid=150
2025-07-15T14:23:23,863 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9020, pid=176
2025-07-15T14:23:23,864 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:23,864 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:23,864 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:23,865 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403865
2025-07-15T14:23:23,864 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9018
2025-07-15T14:23:23,865 [INFO ] W-9043-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403865
2025-07-15T14:23:23,865 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403865
2025-07-15T14:23:23,865 [INFO ] W-9028-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403865
2025-07-15T14:23:23,865 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9028.
2025-07-15T14:23:23,865 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9042, pid=352
2025-07-15T14:23:23,866 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:23,867 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,868 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - [PID]374
2025-07-15T14:23:23,868 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9012, pid=162
2025-07-15T14:23:23,868 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:23,868 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9046
2025-07-15T14:23:23,868 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,869 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:23,870 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,871 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,871 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - [PID]173
2025-07-15T14:23:23,871 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,872 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,872 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:23,872 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9019
2025-07-15T14:23:23,874 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403874
2025-07-15T14:23:23,874 [INFO ] W-9016-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403874
2025-07-15T14:23:23,874 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,875 [INFO ] W-9036-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:23,874 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9016.
2025-07-15T14:23:23,875 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - [PID]352
2025-07-15T14:23:23,876 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:23,876 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9042
2025-07-15T14:23:23,876 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9032, pid=229
2025-07-15T14:23:23,877 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:23,876 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,878 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,881 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9001, pid=141
2025-07-15T14:23:23,882 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,882 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:23,882 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - [PID]176
2025-07-15T14:23:23,882 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,882 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9014.
2025-07-15T14:23:23,883 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,883 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403883
2025-07-15T14:23:23,883 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:23,883 [INFO ] W-9014-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403883
2025-07-15T14:23:23,883 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9020
2025-07-15T14:23:23,885 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,889 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,889 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - [PID]141
2025-07-15T14:23:23,890 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,890 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,898 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - [PID]150
2025-07-15T14:23:23,898 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,898 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,899 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,899 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - [PID]162
2025-07-15T14:23:23,900 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,900 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,903 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:23,903 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - [PID]229
2025-07-15T14:23:23,904 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:23,904 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:23,981 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403981
2025-07-15T14:23:23,981 [INFO ] W-9037-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589403981
2025-07-15T14:23:23,981 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9037.
2025-07-15T14:23:23,992 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9022, pid=179
2025-07-15T14:23:23,993 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:24,000 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9044, pid=359
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - [PID]179
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:24,004 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9022
2025-07-15T14:23:24,006 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:24,010 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9010.
2025-07-15T14:23:24,010 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404010
2025-07-15T14:23:24,010 [INFO ] W-9010-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404010
2025-07-15T14:23:24,013 [INFO ] W-9043-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,020 [INFO ] W-9028-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,020 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9013, pid=163
2025-07-15T14:23:24,020 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:24,023 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=143
2025-07-15T14:23:24,024 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:24,026 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404026
2025-07-15T14:23:24,026 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9018.
2025-07-15T14:23:24,026 [INFO ] W-9018-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404026
2025-07-15T14:23:24,028 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9047, pid=371
2025-07-15T14:23:24,029 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,030 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9046.
2025-07-15T14:23:24,031 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404031
2025-07-15T14:23:24,031 [INFO ] W-9046-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404031
2025-07-15T14:23:24,031 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,032 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - [PID]163
2025-07-15T14:23:24,032 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,032 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,032 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:24,032 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9013
2025-07-15T14:23:24,036 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,037 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - [PID]143
2025-07-15T14:23:24,037 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,081 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404081
2025-07-15T14:23:24,081 [INFO ] W-9005-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404081
2025-07-15T14:23:24,080 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404080
2025-07-15T14:23:24,079 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404079
2025-07-15T14:23:24,080 [INFO ] W-9027-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404080
2025-07-15T14:23:24,079 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404078
2025-07-15T14:23:24,079 [INFO ] W-9034-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404078
2025-07-15T14:23:24,079 [INFO ] W-9021-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404079
2025-07-15T14:23:24,058 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9019.
2025-07-15T14:23:24,152 [INFO ] W-9018-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,075 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404075
2025-07-15T14:23:24,058 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404058
2025-07-15T14:23:24,075 [INFO ] W-9042-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404075
2025-07-15T14:23:24,152 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404152
2025-07-15T14:23:24,058 [INFO ] W-9019-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404058
2025-07-15T14:23:24,152 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404152
2025-07-15T14:23:24,041 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:24,152 [INFO ] W-9020-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404152
2025-07-15T14:23:24,152 [INFO ] W-9033-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404152
2025-07-15T14:23:24,037 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - [PID]359
2025-07-15T14:23:24,153 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,078 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:24,078 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:24,037 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:24,077 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:24,154 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,087 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9033.
2025-07-15T14:23:24,154 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9013.
2025-07-15T14:23:24,078 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:24,154 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,078 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9012
2025-07-15T14:23:24,150 [INFO ] W-9014-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,151 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,154 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - [PID]371
2025-07-15T14:23:24,170 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,170 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,159 [INFO ] W-9016-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,157 [INFO ] W-9046-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,122 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9020.
2025-07-15T14:23:24,170 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:24,080 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9002, pid=146
2025-07-15T14:23:24,154 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:24,061 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9031, pid=230
2025-07-15T14:23:24,101 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9008, pid=153
2025-07-15T14:23:24,121 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9022.
2025-07-15T14:23:24,109 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9006, pid=151
2025-07-15T14:23:24,171 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:24,171 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:24,171 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:24,154 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9044
2025-07-15T14:23:24,037 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2025-07-15T14:23:24,077 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9009, pid=159
2025-07-15T14:23:24,172 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,172 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,078 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9032
2025-07-15T14:23:24,172 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,171 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,172 [INFO ] W-9015-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,171 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,173 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - [PID]230
2025-07-15T14:23:24,171 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,171 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:24,075 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9042.
2025-07-15T14:23:24,172 [INFO ] W-9022-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,078 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9034.
2025-07-15T14:23:24,173 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - [PID]153
2025-07-15T14:23:24,173 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,173 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,079 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9021.
2025-07-15T14:23:24,172 [INFO ] W-9013-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404172
2025-07-15T14:23:24,080 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9027.
2025-07-15T14:23:24,174 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,172 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:24,155 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9015.
2025-07-15T14:23:24,078 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9007
2025-07-15T14:23:24,077 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001
2025-07-15T14:23:24,173 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - [PID]146
2025-07-15T14:23:24,078 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9039, pid=347
2025-07-15T14:23:24,079 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9023, pid=182
2025-07-15T14:23:24,173 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:24,170 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9047
2025-07-15T14:23:24,173 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9031
2025-07-15T14:23:24,080 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9041, pid=354
2025-07-15T14:23:24,079 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9004, pid=148
2025-07-15T14:23:24,080 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9005.
2025-07-15T14:23:24,175 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,176 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:24,173 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,176 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,077 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9038, pid=353
2025-07-15T14:23:24,079 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9040, pid=349
2025-07-15T14:23:24,176 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:24,175 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:24,175 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:24,175 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:24,176 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,176 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:24,177 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - [PID]354
2025-07-15T14:23:24,176 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:24,177 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,176 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,175 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,177 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - [PID]159
2025-07-15T14:23:24,080 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9003, pid=144
2025-07-15T14:23:24,081 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9029, pid=227
2025-07-15T14:23:24,177 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:24,080 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9035, pid=343
2025-07-15T14:23:24,080 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9024, pid=222
2025-07-15T14:23:24,176 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - [PID]151
2025-07-15T14:23:24,178 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:24,178 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:24,177 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,177 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,177 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - [PID]148
2025-07-15T14:23:24,177 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,178 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,181 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,182 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,178 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9009
2025-07-15T14:23:24,182 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - [PID]353
2025-07-15T14:23:24,182 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,182 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,178 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9041
2025-07-15T14:23:24,182 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - [PID]347
2025-07-15T14:23:24,178 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:24,178 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,178 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:24,177 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:24,182 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,182 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,183 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - [PID]182
2025-07-15T14:23:24,178 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,181 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,183 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,184 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,176 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:24,184 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,175 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9008
2025-07-15T14:23:24,184 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:24,184 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:24,176 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002
2025-07-15T14:23:24,178 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:24,184 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9039
2025-07-15T14:23:24,185 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,185 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,185 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - [PID]349
2025-07-15T14:23:24,185 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,184 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - [PID]144
2025-07-15T14:23:24,178 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9006
2025-07-15T14:23:24,186 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:24,184 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9004
2025-07-15T14:23:24,186 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:24,186 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - [PID]227
2025-07-15T14:23:24,184 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,187 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,186 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003
2025-07-15T14:23:24,187 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,186 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,187 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,186 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,186 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9040
2025-07-15T14:23:24,184 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:24,187 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - [PID]343
2025-07-15T14:23:24,188 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,187 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,185 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,188 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - [PID]222
2025-07-15T14:23:24,189 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:24,184 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:24,187 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:24,198 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:24,188 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,201 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9026, pid=225
2025-07-15T14:23:24,216 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:24,213 [INFO ] W-9037-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,187 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9029
2025-07-15T14:23:24,184 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9023
2025-07-15T14:23:24,184 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9038
2025-07-15T14:23:24,198 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9035
2025-07-15T14:23:24,189 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,189 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,218 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,216 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Successfully loaded /opt/conda/lib/python3.10/site-packages/ts/configs/metrics.yaml.
2025-07-15T14:23:24,189 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9024
2025-07-15T14:23:24,218 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - [PID]225
2025-07-15T14:23:24,219 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Torch worker started.
2025-07-15T14:23:24,219 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Python runtime: 3.10.9
2025-07-15T14:23:24,220 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:24,220 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9026
2025-07-15T14:23:24,221 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9012.
2025-07-15T14:23:24,228 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404228
2025-07-15T14:23:24,228 [INFO ] W-9012-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404228
2025-07-15T14:23:24,235 [INFO ] W-9019-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,241 [INFO ] W-9033-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,249 [INFO ] W-9020-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,257 [INFO ] W-9010-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,258 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2025-07-15T14:23:24,266 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404265
2025-07-15T14:23:24,266 [INFO ] W-9000-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404265
2025-07-15T14:23:24,267 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404267
2025-07-15T14:23:24,267 [INFO ] W-9044-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404267
2025-07-15T14:23:24,272 [INFO ] W-9027-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,273 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9044.
2025-07-15T14:23:24,279 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9032.
2025-07-15T14:23:24,279 [INFO ] W-9015-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,279 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404279
2025-07-15T14:23:24,279 [INFO ] W-9032-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404279
2025-07-15T14:23:24,281 [INFO ] W-9022-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,285 [INFO ] W-9021-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,293 [INFO ] W-9034-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,307 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9001.
2025-07-15T14:23:24,307 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404307
2025-07-15T14:23:24,307 [INFO ] W-9001-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404307
2025-07-15T14:23:24,308 [INFO ] W-9005-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,316 [INFO ] W-9042-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,788 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404788
2025-07-15T14:23:24,788 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404788
2025-07-15T14:23:24,787 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9047.
2025-07-15T14:23:24,792 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404791
2025-07-15T14:23:24,792 [INFO ] W-9003-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404791
2025-07-15T14:23:24,792 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9038.
2025-07-15T14:23:24,793 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9039.
2025-07-15T14:23:24,791 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9008.
2025-07-15T14:23:24,793 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9029.
2025-07-15T14:23:24,793 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9035.
2025-07-15T14:23:24,794 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9003.
2025-07-15T14:23:24,790 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9041.
2025-07-15T14:23:24,789 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9004.
2025-07-15T14:23:24,789 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9006.
2025-07-15T14:23:24,789 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9002.
2025-07-15T14:23:24,794 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404794
2025-07-15T14:23:24,788 [INFO ] W-9047-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404788
2025-07-15T14:23:24,794 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404794
2025-07-15T14:23:24,795 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404795
2025-07-15T14:23:24,788 [INFO ] W-9007-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404788
2025-07-15T14:23:24,788 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9007.
2025-07-15T14:23:24,794 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9040.
2025-07-15T14:23:24,827 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404827
2025-07-15T14:23:24,795 [INFO ] W-9029-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404795
2025-07-15T14:23:24,794 [INFO ] W-9038-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404794
2025-07-15T14:23:24,794 [INFO ] W-9035-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404794
2025-07-15T14:23:24,827 [INFO ] W-9023-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404827
2025-07-15T14:23:24,827 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404827
2025-07-15T14:23:24,827 [INFO ] W-9006-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404827
2025-07-15T14:23:24,850 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9023.
2025-07-15T14:23:24,858 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404858
2025-07-15T14:23:24,859 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,858 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9026.
2025-07-15T14:23:24,859 [INFO ] W-9039-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9040-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9026-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,859 [INFO ] W-9004-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404859
2025-07-15T14:23:24,858 [INFO ] W-9041-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404858
2025-07-15T14:23:24,891 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9009.
2025-07-15T14:23:24,891 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404891
2025-07-15T14:23:24,891 [INFO ] W-9009-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404891
2025-07-15T14:23:24,890 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404890
2025-07-15T14:23:24,890 [INFO ] W-9008-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404890
2025-07-15T14:23:24,890 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404890
2025-07-15T14:23:24,858 [INFO ] W-9013-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,890 [INFO ] W-9002-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404890
2025-07-15T14:23:24,858 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9031.
2025-07-15T14:23:24,901 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9024.
2025-07-15T14:23:24,905 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404905
2025-07-15T14:23:24,905 [INFO ] W-9024-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404905
2025-07-15T14:23:24,914 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404914
2025-07-15T14:23:24,914 [INFO ] W-9031-model_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1752589404914
2025-07-15T14:23:24,986 [INFO ] W-9029-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,987 [INFO ] W-9007-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,993 [INFO ] W-9039-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:24,993 [INFO ] W-9044-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,001 [INFO ] W-9000-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,002 [INFO ] W-9032-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,002 [INFO ] W-9012-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,002 [INFO ] W-9001-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,002 [INFO ] W-9047-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,003 [INFO ] W-9003-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,061 [INFO ] W-9006-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,105 [INFO ] W-9035-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,146 [INFO ] W-9038-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,146 [INFO ] W-9041-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,158 [INFO ] W-9009-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,159 [INFO ] W-9002-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,165 [INFO ] W-9004-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,170 [INFO ] W-9023-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,173 [INFO ] W-9024-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,190 [INFO ] W-9031-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,202 [INFO ] W-9040-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,210 [INFO ] W-9008-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
2025-07-15T14:23:25,229 [INFO ] W-9026-model_1.0-stdout MODEL_LOG - model_name: model, batchSize: 1
